{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b795342a-7517-4886-b9e7-0cd7dff4ea44",
   "metadata": {},
   "source": [
    "Install Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1c65832-d841-44a7-8a1f-884627b5e8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: torch>=1.3.1 in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from torchmetrics) (1.8.1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from torch>=1.3.1->torchmetrics) (1.20.2)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from torch>=1.3.1->torchmetrics) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb --upgrade\n",
    "!pip install pytorch-lightning\n",
    "!pip install segmentation-models-pytorch\n",
    "!pip install albumentations\n",
    "!pip install python-dotenv\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6948814-dd3b-4e5e-afc6-8c5fd333c5a5",
   "metadata": {},
   "source": [
    "Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770390a6-37ae-4dce-af77-a0f2f4a2bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://drive.google.com/file/d//view?usp=sharing\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1mQCNp8dq499qnJI0YCc0hTVfmm4ppxO5' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1mQCNp8dq499qnJI0YCc0hTVfmm4ppxO5\" -O \"download.tar.gz\" && rm -rf /tmp/cookies.txt\n",
    "!tar -xvf download.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb0efbb-756a-4fb1-bc17-a35f607100fd",
   "metadata": {},
   "source": [
    "# Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a1b223-8e29-4ca4-af92-1914955fab86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "928c6ff2-7976-4fbb-89f4-30fb183a4c39",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9721225a-1517-4b2a-ab84-a8e87035965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensor\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b440c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamPredictionDataset(Dataset):\n",
    "    \"\"\"Beam Prediction dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, file_path: str,\n",
    "                 label_file_path: str,\n",
    "                 reshape: bool=False,\n",
    "                 transforms: Optional[transforms.Compose] = None,\n",
    "                 preprocessing_fn: Optional[transforms.Compose] = None) -> None:\n",
    "        \"\"\"\n",
    "        Init the Dataset\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.label_file_path = label_file_path\n",
    "        \n",
    "        self.data = np.load(file_path)\n",
    "        self.data = self.data.transpose((1, 0))\n",
    "        \n",
    "        self.label = np.load(label_file_path)\n",
    "#         pdb.set_trace()\n",
    "        \n",
    "        assert len(self.label) == len(self.data)\n",
    "        # reshape is true\n",
    "        # num_users x num_channels x num_antennas x real/imaginary\n",
    "        if reshape:\n",
    "            self.data = self.data.reshape((2, 4, 32, -1))\n",
    "            self.data = self.data.transpose((3, 2, 1, 0))\n",
    "            \n",
    "        self.preprocessing_fn = preprocessing_fn\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the total length of dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Gets an item from dataset\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        user_data = self.data[idx]\n",
    "        \n",
    "        if self.preprocessing_fn is not None:\n",
    "            user_data = self.preprocessing_fn(user_data)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            user_data = self.transforms(user_data)\n",
    "        \n",
    "        label = self.label[idx]\n",
    "        label = torch.Tensor(label).type(torch.int64) - 1\n",
    "        return user_data, label\n",
    "    \n",
    "def transform(x: np.array) -> torch.Tensor:\n",
    "    # mean normalize\n",
    "    x -= x.mean()\n",
    "    x /= x.std()\n",
    "    x = torch.Tensor(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d379ca-5d25-4285-b0ff-701e75893bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 1.1344,  1.1642,  0.8118,  0.1093, -0.2929,  0.3619,  1.0790,  1.3874,\n",
      "         1.2894,  1.1469,  1.3742,  0.6998, -0.4009,  0.3625,  0.8699,  1.1849,\n",
      "         0.6786,  1.1753,  1.1628,  1.0550, -0.8943, -0.7125,  0.3022,  1.0900,\n",
      "         0.8706,  1.3478,  1.5702,  0.9558, -1.6566, -0.7382,  0.0148,  0.6442,\n",
      "         0.3017,  0.8905,  0.9791,  1.1644, -0.9876, -0.7922, -0.4629,  0.3374,\n",
      "        -0.0516,  0.6355,  1.2137,  1.3104, -1.2456, -1.1153, -1.0029,  0.0712,\n",
      "        -0.3255,  0.3647,  1.0288,  1.1176, -1.1510, -1.2242, -1.2269, -0.4542,\n",
      "        -0.7970, -0.4256,  0.9413,  1.4918, -0.9748, -1.5398, -1.6161, -0.4450,\n",
      "        -1.1006, -0.9013,  0.4272,  1.0205, -0.8424, -1.2304, -1.5746, -1.4980,\n",
      "        -1.5050, -0.9478, -0.2943,  0.4626, -0.4176, -1.3170, -1.5857, -1.3130,\n",
      "        -1.2471, -1.1989, -0.6621,  0.2399, -0.2827, -1.0135, -1.6343, -1.5665,\n",
      "        -1.4390, -1.5518, -0.7836, -0.4450, -0.0606, -0.6873, -1.3370, -2.0944,\n",
      "        -1.3866, -1.2450, -1.3194, -0.6425,  0.7051, -0.0322, -1.0300, -1.2306,\n",
      "        -0.6418, -1.6214, -1.3991, -0.9170,  0.9509,  0.4661, -0.6956, -0.8484,\n",
      "        -0.9170, -1.3425, -1.5632, -1.4795,  1.4220,  0.5489,  0.4026, -0.5844,\n",
      "        -0.6274, -1.2085, -1.7199, -1.2470,  1.5720,  1.2481,  0.3709,  0.0025,\n",
      "         0.3596, -0.8391, -1.3560, -1.4393,  1.5227,  1.0183,  0.8746, -0.1959,\n",
      "         0.3806, -0.0644, -1.1502, -1.6148,  1.1727,  1.3091,  1.0675,  0.4314,\n",
      "         1.0033,  0.0746, -0.6809, -1.2830,  1.1760,  1.6166,  1.5842,  0.6260,\n",
      "         1.1363,  0.2335, -0.0576, -1.0852,  0.6769,  1.3474,  1.4323,  1.1049,\n",
      "         1.5561,  0.5584,  0.0851, -0.4431,  0.5574,  0.8314,  1.7251,  0.9947,\n",
      "         1.3336,  1.2545,  0.2566, -0.4365, -0.1540,  0.6379,  1.1497,  1.0744,\n",
      "         1.1799,  1.3945,  0.7851,  0.2137, -0.2622,  0.1544,  1.4368,  1.8656,\n",
      "         1.3089,  1.3896,  1.0659,  0.2861, -0.3666,  0.1218,  0.7796,  1.2413,\n",
      "         1.2102,  1.3221,  1.0344,  0.9304, -1.0877, -0.1499,  0.3859,  1.0914,\n",
      "         0.4617,  0.7131,  1.6144,  1.1880, -1.0281, -1.3422,  0.1930,  0.9728,\n",
      "         0.1454,  0.8132,  1.3767,  0.8216, -1.3210, -0.6237, -0.2125, -0.0454,\n",
      "        -0.3330,  0.3443,  0.7524,  0.9035, -1.2856, -0.2620, -0.4970, -0.2679,\n",
      "        -0.8429,  0.5761,  0.9023,  1.2007, -1.4464, -1.1691, -0.6407, -0.2095,\n",
      "        -0.7193,  0.1202,  0.4905,  1.4410, -1.2580, -1.2274, -1.1168, -0.4818,\n",
      "        -0.5149, -0.4690,  0.3170,  0.8014, -0.6843, -1.1411, -0.9833, -0.9430,\n",
      "        -0.6822, -0.7225, -0.5029,  0.7130, -0.4280, -0.8024, -1.1280, -0.9917]), tensor([36]))\n"
     ]
    }
   ],
   "source": [
    "# example ds\n",
    "\n",
    "ds = BeamPredictionDataset(\n",
    "    file_path='./Dataset_-17.3375dB/-17.3375dB_inpTrain.npy',\n",
    "    label_file_path='./Dataset_-17.3375dB/-17.3375dB_labelTrain.npy',\n",
    "    transforms=transform\n",
    ")\n",
    "it = iter(ds)\n",
    "out = next(it)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569287fc-a66a-487b-9de4-9918e86979dc",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48e84e46-5c5f-4886-80ab-8163ebd91780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "import wandb\n",
    "from argparse import ArgumentParser\n",
    "import segmentation_models_pytorch as smp\n",
    "from typing import Tuple\n",
    "\n",
    "import torchmetrics \n",
    "import pdb\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class BeamClassifier(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, hparams) -> None:\n",
    "        \"\"\"\n",
    "        Downloading Backbone and defining structure of model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # args from argparser\n",
    "        self.hparams = hparams\n",
    "        in_ch = self.hparams.in_ch\n",
    "        out_ch = self.hparams.out_ch\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_ch, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(512, out_ch),\n",
    "        )\n",
    "        \n",
    "        self.acc_metric = torchmetrics.Accuracy()\n",
    "        self.F1_metric = torchmetrics.F1(num_classes=self.hparams.out_ch)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Forward step of model.\n",
    "        \"\"\"\n",
    "#         pdb.set_trace()\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def loss_fn(self, pred: torch.Tensor, y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Loss function used for model\"\"\"\n",
    "        y_sq = y.squeeze(-1)\n",
    "        loss = F.cross_entropy(pred, y_sq)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self) -> torch.optim:\n",
    "        # REQUIRED\n",
    "        # can return multiple optimizers and learning_rate schedulers\n",
    "        opt = torch.optim.Adam(self.model.parameters(),\n",
    "                               lr=self.hparams.learning_rate)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            opt, self.hparams.max_nb_epochs, self.hparams.learning_rate)\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "#         lr_scheduler = None\n",
    "        return [opt], [lr_scheduler]\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Define the data loader for training data\"\"\"\n",
    "        # REQUIRED\n",
    "        return DataLoader(BeamPredictionDataset(\n",
    "                                file_path='./Dataset_-17.3375dB/-17.3375dB_inpTrain.npy',\n",
    "                                label_file_path='./Dataset_-17.3375dB/-17.3375dB_labelTrain.npy',\n",
    "                                transforms=transform\n",
    "                            ),\n",
    "                          batch_size=self.hparams.batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "    def training_step(self, batch: list, batch_idx: int) -> dict:\n",
    "        \"\"\"Backward step of model\"\"\"\n",
    "        # REQUIRED\n",
    "        x, y = batch\n",
    "        pred = self.forward(x)\n",
    "\n",
    "        loss = self.loss_fn(pred, y)\n",
    "        \n",
    "        pred = F.softmax(pred, dim=-1)\n",
    "        y_sq = y.squeeze(-1)\n",
    "        acc = self.acc_metric(pred, y_sq)\n",
    "        f1 = self.F1_metric(pred, y_sq)\n",
    "        \n",
    "        if self.lr_scheduler is not None:\n",
    "            lr = self.lr_scheduler.get_last_lr()[0]\n",
    "\n",
    "        if(batch_idx % self.hparams.wandb_log_num_iter == 0):\n",
    "            wandb.log({\n",
    "                'train_loss': loss,\n",
    "            })\n",
    "            \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'train_acc': acc,\n",
    "            'train_f1': f1\n",
    "        }\n",
    "    \n",
    "    def training_epoch_end(self, outputs: list) -> None:\n",
    "        acc = self.acc_metric.compute()\n",
    "        f1 = self.F1_metric.compute()\n",
    "        \n",
    "        if self.lr_scheduler is not None:\n",
    "            lr = self.lr_scheduler.get_last_lr()[0]\n",
    "        else:\n",
    "            lr = self.hparams.learning_rate\n",
    "        logs = {\n",
    "            'lr': lr,\n",
    "            'train_acc': acc,\n",
    "            'train_f1': f1\n",
    "        }\n",
    "        wandb.log(logs)\n",
    "        self.log_dict(logs)\n",
    "    \n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Define the data loader for validation data\"\"\"\n",
    "        # OPTIONAL\n",
    "        return DataLoader(BeamPredictionDataset(\n",
    "                                file_path='./Dataset_-17.3375dB/-17.3375dB_inpVal.npy',\n",
    "                                label_file_path='./Dataset_-17.3375dB/-17.3375dB_labelVal.npy',\n",
    "                                transforms=transform\n",
    "                            ),\n",
    "                          batch_size=self.hparams.batch_size)\n",
    "\n",
    "    def validation_step(self, batch: list, batch_idx: torch.Tensor) -> dict:\n",
    "        \"\"\"Validation step to be carried out on validation data.\"\"\"\n",
    "        # REQUIRED\n",
    "        # pdb.set_trace()\n",
    "        x, y = batch\n",
    "        \n",
    "        pred = self.forward(x)\n",
    "\n",
    "        loss = self.loss_fn(pred, y)\n",
    "        \n",
    "        pred = F.softmax(pred, dim=-1)\n",
    "        y_sq = y.squeeze(-1)\n",
    "        acc = self.acc_metric(pred, y_sq)\n",
    "        f1 = self.F1_metric(pred, y_sq)\n",
    "\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc,\n",
    "            'val_f1': f1\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs: list) -> None:\n",
    "        \"\"\"Use results from each validation step to generate validation stats at epoch end\"\"\"\n",
    "        val_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        val_acc = self.acc_metric.compute()\n",
    "        val_f1 = self.F1_metric.compute()\n",
    "        \n",
    "        logs = {\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'val_f1': val_f1\n",
    "        }\n",
    "        wandb.log(logs)\n",
    "        self.log_dict(logs)\n",
    "\n",
    "    def load_encoder_weights(self) -> None:\n",
    "        \"\"\"Loads encoder weights from ckpt\"\"\"\n",
    "        ckpt = torch.load(self.hparams.encoder_ckpt_path)\n",
    "        pretrained_dict = ckpt['state_dict']\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if (\n",
    "            'encoder' in k) and (k in model_dict)}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.load_state_dict(model_dict)\n",
    "\n",
    "    def load_model_weights_from_ckpt(self) -> None:\n",
    "        \"\"\"Load model weights to model on cpu\"\"\"\n",
    "        ckpt = torch.load(self.hparams.model_ckpt_path,\n",
    "                          map_location=torch.device('cpu'))\n",
    "        pretrained_dict = ckpt['state_dict']\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k,\n",
    "                           v in pretrained_dict.items() if (k in model_dict)}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.load_state_dict(model_dict)\n",
    "        \n",
    "    def _get_learning_rate(self) -> float:\n",
    "        i = 0\n",
    "        for param_group in self._optimizer.param_groups:\n",
    "            if i == 0:\n",
    "                learning_rate = param_group[\"lr\"]\n",
    "            else:\n",
    "                if learning_rate != param_group[\"lr\"]:\n",
    "                    raise ValueError(\n",
    "                        \"different param groups have different lr\")\n",
    "        return learning_rate\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n",
    "        \"\"\"\n",
    "        Specify the hyperparams for this LightningModule\n",
    "        \"\"\"\n",
    "        # MODEL specific arguments\n",
    "        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "        parser.add_argument('--learning_rate', default=0.02, type=float)\n",
    "        parser.add_argument('--batch_size', default=32, type=int)\n",
    "        parser.add_argument('--in_ch', default=256, type=int)\n",
    "        parser.add_argument('--out_ch', default=64, type=int)\n",
    "        parser.add_argument('--max_nb_epochs', default=1, type=int)\n",
    "        return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "089fff89-0a41-4ee7-9954-7feb94bd577d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0360, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser, Namespace\n",
    "args_str = [\n",
    "        # model related args\n",
    "        '--max_nb_epochs=1',\n",
    "        '--learning_rate=1e-3',\n",
    "        '--batch_size=16',\n",
    "        '--in_ch=256',\n",
    "        '--out_ch=64',\n",
    "]\n",
    "parser = ArgumentParser(add_help=False)\n",
    "parser = BeamClassifier.add_model_specific_args(parser)\n",
    "args= parser.parse_args(args_str)\n",
    "\n",
    "model = BeamClassifier(args)\n",
    "train_dl = model.train_dataloader()\n",
    "it = iter(train_dl)\n",
    "x, y = next(it)\n",
    "\n",
    "\n",
    "pred = model(x)\n",
    "loss = model.loss_fn(pred, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3697609-9464-472d-8433-2a7e0b8787c7",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "308a8cd8-0086-46c0-972d-104f787c18f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_str = ['--tpu_cores=0',\n",
    "        '--progress_bar_refresh_rate=20',\n",
    "        '--wandb_run_name=baseline',\n",
    "        '--wandb_project_name=Beam Prediction',\n",
    "        '--wandb_log_num_iter=1',\n",
    "        '--gpus=0',\n",
    "        # model related args\n",
    "        '--max_nb_epochs=100',\n",
    "        '--learning_rate=5e-3',\n",
    "        '--batch_size=128',\n",
    "        '--in_ch=256',\n",
    "        '--out_ch=64',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bf4ac2e-b316-459a-a66c-d188569b2237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "PROJECT_ROOT = os.path.dirname(os.path.abspath('.'))\n",
    "load_dotenv(dotenv_path=os.path.join(PROJECT_ROOT, '.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de7ad7-ad9a-4ded-8c30-a1b433c91b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2s35q6av) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 91553<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ubuntu/619/wandb/run-20210417_093016-2s35q6av/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ubuntu/619/wandb/run-20210417_093016-2s35q6av/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>val_loss</td><td>1.45293</td></tr><tr><td>val_acc</td><td>0.23706</td></tr><tr><td>val_f1</td><td>0.23706</td></tr><tr><td>_runtime</td><td>121</td></tr><tr><td>_timestamp</td><td>1618651940</td></tr><tr><td>_step</td><td>3025</td></tr><tr><td>train_loss</td><td>1.80217</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_acc</td><td>0.22442</td></tr><tr><td>train_f1</td><td>0.22442</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>val_loss</td><td>█▃▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▇▇█</td></tr><tr><td>val_f1</td><td>▁▄▆▇▇█</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▇▇▆▅▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂▂▁▁▂▂▁▂▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▇█</td></tr><tr><td>train_f1</td><td>▁▄▅▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">beam_trail_1</strong>: <a href=\"https://wandb.ai/sagarkaushik98/Beam%20Prediction/runs/2s35q6av\" target=\"_blank\">https://wandb.ai/sagarkaushik98/Beam%20Prediction/runs/2s35q6av</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2s35q6av). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">beam_trail_1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sagarkaushik98/Beam%20Prediction\" target=\"_blank\">https://wandb.ai/sagarkaushik98/Beam%20Prediction</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sagarkaushik98/Beam%20Prediction/runs/1neu2jya\" target=\"_blank\">https://wandb.ai/sagarkaushik98/Beam%20Prediction/runs/1neu2jya</a><br/>\n",
       "                Run data is saved locally in <code>/home/ubuntu/619/wandb/run-20210417_093324-1neu2jya</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | model      | Sequential | 1.2 M \n",
      "1 | acc_metric | Accuracy   | 0     \n",
      "2 | F1_metric  | F1         | 0     \n",
      "------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.881     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  70%|███████   | 595/850 [00:27<00:11, 21.35it/s, loss=1.86, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  71%|███████   | 600/850 [00:27<00:11, 21.45it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  71%|███████▏  | 606/850 [00:28<00:11, 21.58it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  72%|███████▏  | 612/850 [00:28<00:10, 21.72it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  73%|███████▎  | 618/850 [00:28<00:10, 21.85it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  74%|███████▎  | 625/850 [00:28<00:10, 22.01it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  74%|███████▍  | 632/850 [00:28<00:09, 22.17it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  75%|███████▌  | 639/850 [00:28<00:09, 22.32it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  76%|███████▌  | 646/850 [00:28<00:09, 22.48it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  77%|███████▋  | 653/850 [00:28<00:08, 22.63it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  78%|███████▊  | 660/850 [00:28<00:08, 22.78it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  78%|███████▊  | 667/850 [00:29<00:07, 22.93it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  79%|███████▉  | 674/850 [00:29<00:07, 23.08it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  80%|████████  | 681/850 [00:29<00:07, 23.23it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  81%|████████  | 688/850 [00:29<00:06, 23.38it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  82%|████████▏ | 695/850 [00:29<00:06, 23.51it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  83%|████████▎ | 702/850 [00:29<00:06, 23.66it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  83%|████████▎ | 709/850 [00:29<00:05, 23.80it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  84%|████████▍ | 716/850 [00:29<00:05, 23.94it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  85%|████████▌ | 723/850 [00:30<00:05, 24.08it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  86%|████████▌ | 730/850 [00:30<00:04, 24.22it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  87%|████████▋ | 737/850 [00:30<00:04, 24.36it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  88%|████████▊ | 744/850 [00:30<00:04, 24.50it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  88%|████████▊ | 751/850 [00:30<00:04, 24.64it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  89%|████████▉ | 758/850 [00:30<00:03, 24.77it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  90%|█████████ | 765/850 [00:30<00:03, 24.91it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  91%|█████████ | 772/850 [00:30<00:03, 25.05it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  92%|█████████▏| 780/850 [00:30<00:02, 25.23it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  93%|█████████▎| 788/850 [00:31<00:02, 25.39it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  94%|█████████▎| 796/850 [00:31<00:02, 25.53it/s, loss=1.86, v_num=]\n",
      "Validating:  79%|███████▉  | 201/255 [00:03<00:00, 63.77it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 804/850 [00:31<00:01, 25.68it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  96%|█████████▌| 812/850 [00:31<00:01, 25.83it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  96%|█████████▋| 820/850 [00:31<00:01, 25.97it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  97%|█████████▋| 828/850 [00:31<00:00, 26.11it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  98%|█████████▊| 836/850 [00:31<00:00, 26.26it/s, loss=1.86, v_num=]\n",
      "Epoch 0:  99%|█████████▉| 844/850 [00:31<00:00, 26.41it/s, loss=1.86, v_num=]\n",
      "Epoch 0: 100%|██████████| 850/850 [00:32<00:00, 26.50it/s, loss=1.86, v_num=]\n",
      "Epoch 1:  70%|███████   | 595/850 [00:28<00:12, 20.72it/s, loss=1.71, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  71%|███████   | 600/850 [00:28<00:12, 20.81it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  72%|███████▏  | 608/850 [00:28<00:11, 21.00it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  72%|███████▏  | 616/850 [00:29<00:11, 21.20it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  73%|███████▎  | 624/850 [00:29<00:10, 21.39it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  74%|███████▍  | 632/850 [00:29<00:10, 21.59it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  75%|███████▌  | 640/850 [00:29<00:09, 21.77it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  76%|███████▌  | 648/850 [00:29<00:09, 21.96it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  77%|███████▋  | 656/850 [00:29<00:08, 22.16it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  78%|███████▊  | 664/850 [00:29<00:08, 22.35it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  79%|███████▉  | 672/850 [00:29<00:07, 22.53it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  80%|████████  | 680/850 [00:29<00:07, 22.72it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  81%|████████  | 688/850 [00:30<00:07, 22.91it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  82%|████████▏ | 696/850 [00:30<00:06, 23.09it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  83%|████████▎ | 704/850 [00:30<00:06, 23.27it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  84%|████████▍ | 712/850 [00:30<00:05, 23.45it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  85%|████████▍ | 720/850 [00:30<00:05, 23.63it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  86%|████████▌ | 728/850 [00:30<00:05, 23.81it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  87%|████████▋ | 736/850 [00:30<00:04, 23.99it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  88%|████████▊ | 744/850 [00:30<00:04, 24.17it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  88%|████████▊ | 752/850 [00:30<00:04, 24.34it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  89%|████████▉ | 760/850 [00:31<00:03, 24.50it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  90%|█████████ | 768/850 [00:31<00:03, 24.57it/s, loss=1.71, v_num=]\n",
      "Validating:  68%|██████▊   | 173/255 [00:02<00:01, 52.74it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 776/850 [00:31<00:03, 24.61it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  92%|█████████▏| 784/850 [00:31<00:02, 24.70it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  93%|█████████▎| 792/850 [00:31<00:02, 24.84it/s, loss=1.71, v_num=]\n",
      "Validating:  77%|███████▋  | 197/255 [00:03<00:01, 45.30it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 800/850 [00:32<00:02, 24.99it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  95%|█████████▌| 808/850 [00:32<00:01, 25.13it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  96%|█████████▌| 816/850 [00:32<00:01, 25.27it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  97%|█████████▋| 824/850 [00:32<00:01, 25.40it/s, loss=1.71, v_num=]\n",
      "Validating:  90%|████████▉ | 229/255 [00:03<00:00, 53.49it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 832/850 [00:32<00:00, 25.51it/s, loss=1.71, v_num=]\n",
      "Epoch 1:  99%|█████████▉| 840/850 [00:32<00:00, 25.56it/s, loss=1.71, v_num=]\n",
      "Validating:  96%|█████████▋| 246/255 [00:04<00:00, 39.85it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 850/850 [00:33<00:00, 25.67it/s, loss=1.71, v_num=]\n",
      "Epoch 2:  70%|███████   | 595/850 [00:29<00:12, 20.26it/s, loss=1.59, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  71%|███████   | 600/850 [00:29<00:12, 20.37it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  72%|███████▏  | 608/850 [00:29<00:11, 20.56it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  72%|███████▏  | 616/850 [00:29<00:11, 20.76it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  73%|███████▎  | 624/850 [00:29<00:10, 20.95it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  74%|███████▍  | 632/850 [00:29<00:10, 21.15it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  75%|███████▌  | 640/850 [00:29<00:09, 21.34it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  76%|███████▌  | 648/850 [00:30<00:09, 21.52it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  77%|███████▋  | 656/850 [00:30<00:08, 21.71it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  78%|███████▊  | 664/850 [00:30<00:08, 21.90it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  79%|███████▉  | 672/850 [00:30<00:08, 22.09it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  80%|████████  | 680/850 [00:30<00:07, 22.27it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  81%|████████  | 688/850 [00:30<00:07, 22.46it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  82%|████████▏ | 696/850 [00:30<00:06, 22.64it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  83%|████████▎ | 704/850 [00:30<00:06, 22.83it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  84%|████████▍ | 712/850 [00:30<00:05, 23.01it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  85%|████████▍ | 720/850 [00:31<00:05, 23.19it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  86%|████████▌ | 728/850 [00:31<00:05, 23.37it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  87%|████████▋ | 736/850 [00:31<00:04, 23.55it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  88%|████████▊ | 744/850 [00:31<00:04, 23.72it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  88%|████████▊ | 752/850 [00:31<00:04, 23.90it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  89%|████████▉ | 760/850 [00:31<00:03, 24.07it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  90%|█████████ | 768/850 [00:31<00:03, 24.25it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  91%|█████████▏| 776/850 [00:31<00:03, 24.42it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  92%|█████████▏| 784/850 [00:31<00:02, 24.59it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  93%|█████████▎| 792/850 [00:31<00:02, 24.76it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  94%|█████████▍| 800/850 [00:32<00:02, 24.93it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  95%|█████████▌| 808/850 [00:32<00:01, 25.08it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  96%|█████████▌| 816/850 [00:32<00:01, 25.22it/s, loss=1.59, v_num=]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  97%|█████████▋| 824/850 [00:32<00:01, 25.37it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  98%|█████████▊| 832/850 [00:32<00:00, 25.52it/s, loss=1.59, v_num=]\n",
      "Epoch 2:  99%|█████████▉| 840/850 [00:32<00:00, 25.66it/s, loss=1.59, v_num=]\n",
      "Validating:  96%|█████████▌| 245/255 [00:03<00:00, 64.32it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 850/850 [00:32<00:00, 25.83it/s, loss=1.59, v_num=]\n",
      "Epoch 3:  70%|███████   | 595/850 [00:28<00:12, 20.58it/s, loss=1.51, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  71%|███████   | 600/850 [00:29<00:12, 20.68it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  72%|███████▏  | 608/850 [00:29<00:11, 20.86it/s, loss=1.51, v_num=]\n",
      "Validating:   5%|▌         | 13/255 [00:00<00:03, 61.41it/s]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 616/850 [00:29<00:11, 21.04it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  73%|███████▎  | 624/850 [00:29<00:10, 21.22it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  74%|███████▍  | 632/850 [00:29<00:10, 21.42it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  75%|███████▌  | 640/850 [00:29<00:09, 21.61it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  76%|███████▌  | 648/850 [00:29<00:09, 21.81it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  77%|███████▋  | 656/850 [00:29<00:08, 22.00it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  78%|███████▊  | 664/850 [00:29<00:08, 22.19it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  79%|███████▉  | 672/850 [00:30<00:07, 22.37it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  80%|████████  | 680/850 [00:30<00:07, 22.54it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  81%|████████  | 688/850 [00:30<00:07, 22.71it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  82%|████████▏ | 696/850 [00:30<00:06, 22.88it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  83%|████████▎ | 704/850 [00:30<00:06, 23.04it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  84%|████████▍ | 712/850 [00:30<00:05, 23.21it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  85%|████████▍ | 720/850 [00:30<00:05, 23.37it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  86%|████████▌ | 728/850 [00:30<00:05, 23.53it/s, loss=1.51, v_num=]\n",
      "Validating:  52%|█████▏    | 133/255 [00:02<00:01, 62.91it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 736/850 [00:31<00:04, 23.69it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  88%|████████▊ | 744/850 [00:31<00:04, 23.85it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  88%|████████▊ | 752/850 [00:31<00:04, 24.01it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  89%|████████▉ | 760/850 [00:31<00:03, 24.16it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  90%|█████████ | 768/850 [00:31<00:03, 24.32it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  91%|█████████▏| 776/850 [00:31<00:03, 24.47it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  92%|█████████▏| 784/850 [00:31<00:02, 24.62it/s, loss=1.51, v_num=]\n",
      "Validating:  74%|███████▍  | 189/255 [00:02<00:01, 60.99it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 792/850 [00:31<00:02, 24.77it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  94%|█████████▍| 800/850 [00:32<00:02, 24.91it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  95%|█████████▌| 808/850 [00:32<00:01, 25.05it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  96%|█████████▌| 816/850 [00:32<00:01, 25.20it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  97%|█████████▋| 824/850 [00:32<00:01, 25.35it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  98%|█████████▊| 832/850 [00:32<00:00, 25.50it/s, loss=1.51, v_num=]\n",
      "Epoch 3:  99%|█████████▉| 840/850 [00:32<00:00, 25.67it/s, loss=1.51, v_num=]\n",
      "Epoch 3: 100%|█████████▉| 848/850 [00:32<00:00, 25.83it/s, loss=1.51, v_num=]\n",
      "Epoch 3: 100%|██████████| 850/850 [00:32<00:00, 25.85it/s, loss=1.51, v_num=]\n",
      "Epoch 4:  70%|███████   | 595/850 [00:29<00:12, 20.28it/s, loss=1.44, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  71%|███████   | 600/850 [00:29<00:12, 20.39it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  72%|███████▏  | 608/850 [00:29<00:11, 20.59it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  72%|███████▏  | 616/850 [00:29<00:11, 20.79it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  73%|███████▎  | 624/850 [00:29<00:10, 20.97it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  74%|███████▍  | 632/850 [00:29<00:10, 21.14it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  75%|███████▌  | 640/850 [00:30<00:09, 21.31it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  76%|███████▌  | 648/850 [00:30<00:09, 21.48it/s, loss=1.44, v_num=]\n",
      "Validating:  21%|██        | 53/255 [00:00<00:03, 59.98it/s]\u001b[A\n",
      "Epoch 4:  77%|███████▋  | 656/850 [00:30<00:08, 21.65it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  78%|███████▊  | 664/850 [00:30<00:08, 21.82it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  79%|███████▉  | 672/850 [00:30<00:08, 21.99it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  80%|████████  | 680/850 [00:30<00:07, 22.16it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  81%|████████  | 688/850 [00:30<00:07, 22.33it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  82%|████████▏ | 696/850 [00:30<00:06, 22.49it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  83%|████████▎ | 704/850 [00:31<00:06, 22.66it/s, loss=1.44, v_num=]\n",
      "Validating:  43%|████▎     | 109/255 [00:01<00:02, 61.84it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 712/850 [00:31<00:06, 22.82it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  85%|████████▍ | 720/850 [00:31<00:05, 22.98it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  86%|████████▌ | 728/850 [00:31<00:05, 23.14it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  87%|████████▋ | 736/850 [00:31<00:04, 23.30it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  88%|████████▊ | 744/850 [00:31<00:04, 23.45it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  88%|████████▊ | 752/850 [00:31<00:04, 23.62it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  89%|████████▉ | 760/850 [00:31<00:03, 23.79it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  90%|█████████ | 768/850 [00:32<00:03, 23.96it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  91%|█████████▏| 776/850 [00:32<00:03, 24.12it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  92%|█████████▏| 784/850 [00:32<00:02, 24.28it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  93%|█████████▎| 792/850 [00:32<00:02, 24.45it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  94%|█████████▍| 800/850 [00:32<00:02, 24.61it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  95%|█████████▌| 808/850 [00:32<00:01, 24.78it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  96%|█████████▌| 816/850 [00:32<00:01, 24.94it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  97%|█████████▋| 824/850 [00:32<00:01, 25.10it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  98%|█████████▊| 832/850 [00:32<00:00, 25.27it/s, loss=1.44, v_num=]\n",
      "Epoch 4:  99%|█████████▉| 840/850 [00:33<00:00, 25.43it/s, loss=1.44, v_num=]\n",
      "Epoch 4: 100%|█████████▉| 848/850 [00:33<00:00, 25.59it/s, loss=1.44, v_num=]\n",
      "Epoch 4: 100%|██████████| 850/850 [00:33<00:00, 25.61it/s, loss=1.44, v_num=]\n",
      "Epoch 5:  70%|███████   | 595/850 [00:28<00:12, 20.54it/s, loss=1.46, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  71%|███████   | 600/850 [00:29<00:12, 20.64it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  72%|███████▏  | 608/850 [00:29<00:11, 20.82it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  72%|███████▏  | 616/850 [00:29<00:11, 21.00it/s, loss=1.46, v_num=]\n",
      "Validating:   8%|▊         | 21/255 [00:00<00:03, 61.11it/s]\u001b[A\n",
      "Epoch 5:  73%|███████▎  | 624/850 [00:29<00:10, 21.18it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  74%|███████▍  | 632/850 [00:29<00:10, 21.35it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  75%|███████▌  | 640/850 [00:29<00:09, 21.53it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  76%|███████▌  | 648/850 [00:29<00:09, 21.69it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  77%|███████▋  | 656/850 [00:30<00:08, 21.85it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  78%|███████▊  | 664/850 [00:30<00:08, 22.02it/s, loss=1.46, v_num=]\n",
      "Validating:  27%|██▋       | 69/255 [00:01<00:03, 58.40it/s]\u001b[A\n",
      "Epoch 5:  79%|███████▉  | 672/850 [00:30<00:08, 22.19it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  80%|████████  | 680/850 [00:30<00:07, 22.35it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  81%|████████  | 688/850 [00:30<00:07, 22.49it/s, loss=1.46, v_num=]\n",
      "Validating:  37%|███▋      | 94/255 [00:01<00:03, 51.32it/s]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 696/850 [00:30<00:06, 22.61it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  83%|████████▎ | 704/850 [00:30<00:06, 22.77it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  84%|████████▍ | 712/850 [00:31<00:06, 22.93it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  85%|████████▍ | 720/850 [00:31<00:05, 23.09it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  86%|████████▌ | 728/850 [00:31<00:05, 23.25it/s, loss=1.46, v_num=]\n",
      "Validating:  52%|█████▏    | 133/255 [00:02<00:02, 58.06it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 736/850 [00:31<00:04, 23.40it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  88%|████████▊ | 744/850 [00:31<00:04, 23.56it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  88%|████████▊ | 752/850 [00:31<00:04, 23.72it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  89%|████████▉ | 760/850 [00:31<00:03, 23.87it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  90%|█████████ | 768/850 [00:31<00:03, 24.01it/s, loss=1.46, v_num=]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  91%|█████████▏| 776/850 [00:32<00:03, 24.16it/s, loss=1.46, v_num=]\n",
      "Validating:  71%|███████   | 181/255 [00:03<00:01, 58.72it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 784/850 [00:32<00:02, 24.30it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  93%|█████████▎| 792/850 [00:32<00:02, 24.45it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  94%|█████████▍| 800/850 [00:32<00:02, 24.59it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  95%|█████████▌| 808/850 [00:32<00:01, 24.74it/s, loss=1.46, v_num=]\n",
      "Validating:  84%|████████▎ | 213/255 [00:03<00:00, 59.11it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 816/850 [00:32<00:01, 24.88it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  97%|█████████▋| 824/850 [00:32<00:01, 25.02it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  98%|█████████▊| 832/850 [00:33<00:00, 25.17it/s, loss=1.46, v_num=]\n",
      "Epoch 5:  99%|█████████▉| 840/850 [00:33<00:00, 25.31it/s, loss=1.46, v_num=]\n",
      "Epoch 5: 100%|█████████▉| 848/850 [00:33<00:00, 25.45it/s, loss=1.46, v_num=]\n",
      "Epoch 5: 100%|██████████| 850/850 [00:33<00:00, 25.47it/s, loss=1.46, v_num=]\n",
      "Epoch 6:  70%|███████   | 595/850 [00:28<00:12, 20.52it/s, loss=1.42, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  71%|███████   | 600/850 [00:29<00:12, 20.63it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  72%|███████▏  | 608/850 [00:29<00:11, 20.83it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  72%|███████▏  | 616/850 [00:29<00:11, 21.02it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  73%|███████▎  | 624/850 [00:29<00:10, 21.21it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  74%|███████▍  | 632/850 [00:29<00:10, 21.40it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  75%|███████▌  | 640/850 [00:29<00:09, 21.60it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  76%|███████▌  | 648/850 [00:29<00:09, 21.79it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  77%|███████▋  | 656/850 [00:29<00:08, 21.98it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  78%|███████▊  | 664/850 [00:29<00:08, 22.17it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  79%|███████▉  | 672/850 [00:30<00:07, 22.36it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  80%|████████  | 680/850 [00:30<00:07, 22.55it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  81%|████████  | 688/850 [00:30<00:07, 22.73it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  82%|████████▏ | 696/850 [00:30<00:06, 22.92it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  83%|████████▎ | 704/850 [00:30<00:06, 23.10it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  84%|████████▍ | 712/850 [00:30<00:05, 23.28it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  85%|████████▍ | 720/850 [00:30<00:05, 23.46it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  86%|████████▌ | 728/850 [00:30<00:05, 23.64it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  87%|████████▋ | 736/850 [00:30<00:04, 23.82it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  88%|████████▊ | 744/850 [00:30<00:04, 24.00it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  88%|████████▊ | 752/850 [00:31<00:04, 24.18it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  89%|████████▉ | 760/850 [00:31<00:03, 24.35it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  90%|█████████ | 768/850 [00:31<00:03, 24.53it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  91%|█████████▏| 776/850 [00:31<00:02, 24.68it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  92%|█████████▏| 784/850 [00:31<00:02, 24.85it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  93%|█████████▎| 792/850 [00:31<00:02, 25.02it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  94%|█████████▍| 800/850 [00:31<00:01, 25.19it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  95%|█████████▌| 808/850 [00:31<00:01, 25.35it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  96%|█████████▌| 816/850 [00:31<00:01, 25.52it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  97%|█████████▋| 824/850 [00:32<00:01, 25.68it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  98%|█████████▊| 832/850 [00:32<00:00, 25.85it/s, loss=1.42, v_num=]\n",
      "Epoch 6:  99%|█████████▉| 840/850 [00:32<00:00, 26.01it/s, loss=1.42, v_num=]\n",
      "Epoch 6: 100%|██████████| 850/850 [00:32<00:00, 26.20it/s, loss=1.42, v_num=]\n",
      "Epoch 7:  70%|███████   | 595/850 [00:28<00:12, 20.75it/s, loss=1.4, v_num=] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  71%|███████   | 600/850 [00:28<00:11, 20.85it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  72%|███████▏  | 608/850 [00:28<00:11, 21.03it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  72%|███████▏  | 616/850 [00:29<00:11, 21.22it/s, loss=1.4, v_num=]\n",
      "Validating:   8%|▊         | 21/255 [00:00<00:03, 61.71it/s]\u001b[A\n",
      "Epoch 7:  73%|███████▎  | 624/850 [00:29<00:10, 21.39it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  74%|███████▍  | 632/850 [00:29<00:10, 21.57it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  75%|███████▌  | 640/850 [00:29<00:09, 21.75it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  76%|███████▌  | 648/850 [00:29<00:09, 21.92it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  77%|███████▋  | 656/850 [00:29<00:08, 22.09it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  78%|███████▊  | 664/850 [00:29<00:08, 22.25it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  79%|███████▉  | 672/850 [00:29<00:07, 22.43it/s, loss=1.4, v_num=]\n",
      "Validating:  30%|███       | 77/255 [00:01<00:02, 59.72it/s]\u001b[A\n",
      "Epoch 7:  80%|████████  | 680/850 [00:30<00:07, 22.59it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  81%|████████  | 688/850 [00:30<00:07, 22.76it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  82%|████████▏ | 696/850 [00:30<00:06, 22.93it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  83%|████████▎ | 704/850 [00:30<00:06, 23.09it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  84%|████████▍ | 712/850 [00:30<00:05, 23.26it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  85%|████████▍ | 720/850 [00:30<00:05, 23.42it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  86%|████████▌ | 728/850 [00:30<00:05, 23.58it/s, loss=1.4, v_num=]\n",
      "Validating:  52%|█████▏    | 133/255 [00:02<00:01, 61.52it/s]\u001b[A\n",
      "Epoch 7:  87%|████████▋ | 736/850 [00:31<00:04, 23.73it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  88%|████████▊ | 744/850 [00:31<00:04, 23.91it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  88%|████████▊ | 752/850 [00:31<00:04, 24.08it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  89%|████████▉ | 760/850 [00:31<00:03, 24.24it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  90%|█████████ | 768/850 [00:31<00:03, 24.39it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  91%|█████████▏| 776/850 [00:31<00:03, 24.55it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  92%|█████████▏| 784/850 [00:31<00:02, 24.71it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  93%|█████████▎| 792/850 [00:31<00:02, 24.88it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  94%|█████████▍| 800/850 [00:31<00:01, 25.04it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  95%|█████████▌| 808/850 [00:32<00:01, 25.20it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  96%|█████████▌| 816/850 [00:32<00:01, 25.37it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  97%|█████████▋| 824/850 [00:32<00:01, 25.53it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  98%|█████████▊| 832/850 [00:32<00:00, 25.69it/s, loss=1.4, v_num=]\n",
      "Epoch 7:  99%|█████████▉| 840/850 [00:32<00:00, 25.85it/s, loss=1.4, v_num=]\n",
      "Epoch 7: 100%|█████████▉| 848/850 [00:32<00:00, 26.01it/s, loss=1.4, v_num=]\n",
      "Epoch 7: 100%|██████████| 850/850 [00:32<00:00, 26.04it/s, loss=1.4, v_num=]\n",
      "Epoch 8:  70%|███████   | 595/850 [00:30<00:13, 19.25it/s, loss=1.35, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  71%|███████   | 600/850 [00:30<00:12, 19.36it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  72%|███████▏  | 608/850 [00:31<00:12, 19.55it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  72%|███████▏  | 616/850 [00:31<00:11, 19.74it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  73%|███████▎  | 624/850 [00:31<00:11, 19.92it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  74%|███████▍  | 632/850 [00:31<00:10, 20.11it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  75%|███████▌  | 640/850 [00:31<00:10, 20.29it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  76%|███████▌  | 648/850 [00:31<00:09, 20.47it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  77%|███████▋  | 656/850 [00:31<00:09, 20.66it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  78%|███████▊  | 664/850 [00:31<00:08, 20.84it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  79%|███████▉  | 672/850 [00:31<00:08, 21.02it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  80%|████████  | 680/850 [00:32<00:08, 21.19it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  81%|████████  | 688/850 [00:32<00:07, 21.36it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  82%|████████▏ | 696/850 [00:32<00:07, 21.53it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  83%|████████▎ | 704/850 [00:32<00:06, 21.71it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  84%|████████▍ | 712/850 [00:32<00:06, 21.88it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  85%|████████▍ | 720/850 [00:32<00:05, 22.06it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  86%|████████▌ | 728/850 [00:32<00:05, 22.23it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  87%|████████▋ | 736/850 [00:32<00:05, 22.40it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  88%|████████▊ | 744/850 [00:32<00:04, 22.57it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  88%|████████▊ | 752/850 [00:33<00:04, 22.74it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  89%|████████▉ | 760/850 [00:33<00:03, 22.91it/s, loss=1.35, v_num=]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  90%|█████████ | 768/850 [00:33<00:03, 23.08it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  91%|█████████▏| 776/850 [00:33<00:03, 23.25it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  92%|█████████▏| 784/850 [00:33<00:02, 23.41it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  93%|█████████▎| 792/850 [00:33<00:02, 23.58it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  94%|█████████▍| 800/850 [00:33<00:02, 23.73it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  95%|█████████▌| 808/850 [00:33<00:01, 23.87it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  96%|█████████▌| 816/850 [00:33<00:01, 24.02it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  97%|█████████▋| 824/850 [00:34<00:01, 24.16it/s, loss=1.35, v_num=]\n",
      "Epoch 8:  98%|█████████▊| 832/850 [00:34<00:00, 24.30it/s, loss=1.35, v_num=]\n",
      "Validating:  93%|█████████▎| 237/255 [00:03<00:00, 62.08it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 840/850 [00:34<00:00, 24.44it/s, loss=1.35, v_num=]\n",
      "Epoch 8: 100%|██████████| 850/850 [00:34<00:00, 24.60it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  70%|███████   | 595/850 [00:29<00:12, 20.43it/s, loss=1.35, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  71%|███████   | 600/850 [00:29<00:12, 20.53it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  72%|███████▏  | 608/850 [00:29<00:11, 20.72it/s, loss=1.35, v_num=]\n",
      "Validating:   5%|▌         | 13/255 [00:00<00:03, 61.28it/s]\u001b[A\n",
      "Epoch 9:  72%|███████▏  | 616/850 [00:29<00:11, 20.89it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  73%|███████▎  | 624/850 [00:29<00:10, 21.07it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  74%|███████▍  | 632/850 [00:29<00:10, 21.25it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  75%|███████▌  | 640/850 [00:29<00:09, 21.42it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  76%|███████▌  | 648/850 [00:30<00:09, 21.60it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  77%|███████▋  | 656/850 [00:30<00:08, 21.77it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  78%|███████▊  | 664/850 [00:30<00:08, 21.94it/s, loss=1.35, v_num=]\n",
      "Validating:  27%|██▋       | 69/255 [00:01<00:03, 61.95it/s]\u001b[A\n",
      "Epoch 9:  79%|███████▉  | 672/850 [00:30<00:08, 22.11it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  80%|████████  | 680/850 [00:30<00:07, 22.28it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  81%|████████  | 688/850 [00:30<00:07, 22.44it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  82%|████████▏ | 696/850 [00:30<00:06, 22.62it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  83%|████████▎ | 704/850 [00:30<00:06, 22.80it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  84%|████████▍ | 712/850 [00:30<00:06, 22.99it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  85%|████████▍ | 720/850 [00:31<00:05, 23.17it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  86%|████████▌ | 728/850 [00:31<00:05, 23.35it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  87%|████████▋ | 736/850 [00:31<00:04, 23.52it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  88%|████████▊ | 744/850 [00:31<00:04, 23.70it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  88%|████████▊ | 752/850 [00:31<00:04, 23.87it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  89%|████████▉ | 760/850 [00:31<00:03, 24.04it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  90%|█████████ | 768/850 [00:31<00:03, 24.21it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  91%|█████████▏| 776/850 [00:31<00:03, 24.38it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  92%|█████████▏| 784/850 [00:31<00:02, 24.55it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  93%|█████████▎| 792/850 [00:32<00:02, 24.72it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  94%|█████████▍| 800/850 [00:32<00:02, 24.88it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  95%|█████████▌| 808/850 [00:32<00:01, 25.05it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  96%|█████████▌| 816/850 [00:32<00:01, 25.21it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  97%|█████████▋| 824/850 [00:32<00:01, 25.38it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  98%|█████████▊| 832/850 [00:32<00:00, 25.53it/s, loss=1.35, v_num=]\n",
      "Epoch 9:  99%|█████████▉| 840/850 [00:32<00:00, 25.69it/s, loss=1.35, v_num=]\n",
      "Epoch 9: 100%|██████████| 850/850 [00:32<00:00, 25.88it/s, loss=1.35, v_num=]\n",
      "Epoch 10:  70%|███████   | 595/850 [00:28<00:12, 20.58it/s, loss=1.33, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  71%|███████   | 600/850 [00:29<00:12, 20.68it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  72%|███████▏  | 608/850 [00:29<00:11, 20.86it/s, loss=1.33, v_num=]\n",
      "Validating:   5%|▌         | 13/255 [00:00<00:04, 59.73it/s]\u001b[A\n",
      "Epoch 10:  72%|███████▏  | 616/850 [00:29<00:11, 21.04it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  73%|███████▎  | 624/850 [00:29<00:10, 21.21it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  74%|███████▍  | 632/850 [00:29<00:10, 21.39it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  75%|███████▌  | 640/850 [00:29<00:09, 21.57it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  76%|███████▌  | 648/850 [00:29<00:09, 21.74it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  77%|███████▋  | 656/850 [00:29<00:08, 21.91it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  78%|███████▊  | 664/850 [00:30<00:08, 22.09it/s, loss=1.33, v_num=]\n",
      "Validating:  27%|██▋       | 69/255 [00:01<00:03, 61.09it/s]\u001b[A\n",
      "Epoch 10:  79%|███████▉  | 672/850 [00:30<00:07, 22.25it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  80%|████████  | 680/850 [00:30<00:07, 22.42it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  81%|████████  | 688/850 [00:30<00:07, 22.60it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  82%|████████▏ | 696/850 [00:30<00:06, 22.79it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  83%|████████▎ | 704/850 [00:30<00:06, 22.96it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  84%|████████▍ | 712/850 [00:30<00:05, 23.14it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  85%|████████▍ | 720/850 [00:30<00:05, 23.32it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  86%|████████▌ | 728/850 [00:30<00:05, 23.50it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  87%|████████▋ | 736/850 [00:31<00:04, 23.68it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  88%|████████▊ | 744/850 [00:31<00:04, 23.85it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  88%|████████▊ | 752/850 [00:31<00:04, 24.02it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  89%|████████▉ | 760/850 [00:31<00:03, 24.20it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  90%|█████████ | 768/850 [00:31<00:03, 24.37it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  91%|█████████▏| 776/850 [00:31<00:03, 24.54it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  92%|█████████▏| 784/850 [00:31<00:02, 24.71it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  93%|█████████▎| 792/850 [00:31<00:02, 24.87it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  94%|█████████▍| 800/850 [00:31<00:01, 25.04it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  95%|█████████▌| 808/850 [00:32<00:01, 25.20it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  96%|█████████▌| 816/850 [00:32<00:01, 25.37it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  97%|█████████▋| 824/850 [00:32<00:01, 25.53it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  98%|█████████▊| 832/850 [00:32<00:00, 25.69it/s, loss=1.33, v_num=]\n",
      "Epoch 10:  99%|█████████▉| 840/850 [00:32<00:00, 25.86it/s, loss=1.33, v_num=]\n",
      "Epoch 10: 100%|██████████| 850/850 [00:32<00:00, 26.04it/s, loss=1.33, v_num=]\n",
      "Epoch 11:  70%|███████   | 595/850 [00:28<00:12, 20.64it/s, loss=1.34, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  71%|███████   | 600/850 [00:28<00:12, 20.74it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  72%|███████▏  | 608/850 [00:29<00:11, 20.93it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  72%|███████▏  | 616/850 [00:29<00:11, 21.10it/s, loss=1.34, v_num=]\n",
      "Validating:   8%|▊         | 21/255 [00:00<00:03, 60.78it/s]\u001b[A\n",
      "Epoch 11:  73%|███████▎  | 624/850 [00:29<00:10, 21.28it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  74%|███████▍  | 632/850 [00:29<00:10, 21.46it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  75%|███████▌  | 640/850 [00:29<00:09, 21.63it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  76%|███████▌  | 648/850 [00:29<00:09, 21.81it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  77%|███████▋  | 656/850 [00:29<00:08, 21.98it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  78%|███████▊  | 664/850 [00:29<00:08, 22.16it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  79%|███████▉  | 672/850 [00:30<00:07, 22.33it/s, loss=1.34, v_num=]\n",
      "Validating:  30%|███       | 77/255 [00:01<00:02, 61.85it/s]\u001b[A\n",
      "Epoch 11:  80%|████████  | 680/850 [00:30<00:07, 22.50it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  81%|████████  | 688/850 [00:30<00:07, 22.66it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  82%|████████▏ | 696/850 [00:30<00:06, 22.83it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  83%|████████▎ | 704/850 [00:30<00:06, 23.00it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  84%|████████▍ | 712/850 [00:30<00:05, 23.16it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  85%|████████▍ | 720/850 [00:30<00:05, 23.32it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  86%|████████▌ | 728/850 [00:30<00:05, 23.50it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  87%|████████▋ | 736/850 [00:31<00:04, 23.66it/s, loss=1.34, v_num=]\n",
      "Validating:  55%|█████▌    | 141/255 [00:02<00:01, 64.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  88%|████████▊ | 744/850 [00:31<00:04, 23.82it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  88%|████████▊ | 752/850 [00:31<00:04, 23.97it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  89%|████████▉ | 760/850 [00:31<00:03, 24.13it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  90%|█████████ | 768/850 [00:31<00:03, 24.28it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  91%|█████████▏| 776/850 [00:31<00:03, 24.44it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  92%|█████████▏| 784/850 [00:31<00:02, 24.59it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  93%|█████████▎| 792/850 [00:32<00:02, 24.74it/s, loss=1.34, v_num=]\n",
      "Validating:  77%|███████▋  | 197/255 [00:03<00:00, 61.09it/s]\u001b[A\n",
      "Epoch 11:  94%|█████████▍| 800/850 [00:32<00:02, 24.88it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  95%|█████████▌| 808/850 [00:32<00:01, 25.03it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  96%|█████████▌| 816/850 [00:32<00:01, 25.19it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  97%|█████████▋| 824/850 [00:32<00:01, 25.36it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  98%|█████████▊| 832/850 [00:32<00:00, 25.52it/s, loss=1.34, v_num=]\n",
      "Epoch 11:  99%|█████████▉| 840/850 [00:32<00:00, 25.68it/s, loss=1.34, v_num=]\n",
      "Epoch 11: 100%|██████████| 850/850 [00:32<00:00, 25.86it/s, loss=1.34, v_num=]\n",
      "Epoch 12:  70%|███████   | 595/850 [00:28<00:12, 20.77it/s, loss=1.3, v_num=] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  71%|███████   | 600/850 [00:28<00:11, 20.87it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  72%|███████▏  | 608/850 [00:28<00:11, 21.05it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  72%|███████▏  | 616/850 [00:28<00:11, 21.25it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  73%|███████▎  | 624/850 [00:29<00:10, 21.45it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  74%|███████▍  | 632/850 [00:29<00:10, 21.65it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  75%|███████▌  | 640/850 [00:29<00:09, 21.84it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  76%|███████▌  | 648/850 [00:29<00:09, 22.04it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  77%|███████▋  | 656/850 [00:29<00:08, 22.23it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  78%|███████▊  | 664/850 [00:29<00:08, 22.42it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  79%|███████▉  | 672/850 [00:29<00:07, 22.61it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  80%|████████  | 680/850 [00:29<00:07, 22.80it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  81%|████████  | 688/850 [00:29<00:07, 22.98it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  82%|████████▏ | 696/850 [00:30<00:06, 23.17it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  83%|████████▎ | 704/850 [00:30<00:06, 23.35it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  84%|████████▍ | 712/850 [00:30<00:05, 23.52it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  85%|████████▍ | 720/850 [00:30<00:05, 23.68it/s, loss=1.3, v_num=]\n",
      "Validating:  49%|████▉     | 125/255 [00:01<00:01, 67.78it/s]\u001b[A\n",
      "Epoch 12:  86%|████████▌ | 728/850 [00:30<00:05, 23.84it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  87%|████████▋ | 736/850 [00:30<00:04, 24.00it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  88%|████████▊ | 744/850 [00:30<00:04, 24.17it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  88%|████████▊ | 752/850 [00:30<00:04, 24.31it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  89%|████████▉ | 760/850 [00:31<00:03, 24.46it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  90%|█████████ | 768/850 [00:31<00:03, 24.62it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  91%|█████████▏| 776/850 [00:31<00:02, 24.77it/s, loss=1.3, v_num=]\n",
      "Validating:  71%|███████   | 181/255 [00:02<00:01, 61.16it/s]\u001b[A\n",
      "Epoch 12:  92%|█████████▏| 784/850 [00:31<00:02, 24.92it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  93%|█████████▎| 792/850 [00:31<00:02, 25.07it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  94%|█████████▍| 800/850 [00:31<00:01, 25.22it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  95%|█████████▌| 808/850 [00:31<00:01, 25.39it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  96%|█████████▌| 816/850 [00:31<00:01, 25.55it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  97%|█████████▋| 824/850 [00:32<00:01, 25.70it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  98%|█████████▊| 832/850 [00:32<00:00, 25.85it/s, loss=1.3, v_num=]\n",
      "Epoch 12:  99%|█████████▉| 840/850 [00:32<00:00, 26.00it/s, loss=1.3, v_num=]\n",
      "Epoch 12: 100%|█████████▉| 848/850 [00:32<00:00, 26.17it/s, loss=1.3, v_num=]\n",
      "Epoch 12: 100%|██████████| 850/850 [00:32<00:00, 26.19it/s, loss=1.3, v_num=]\n",
      "Epoch 13:  70%|███████   | 595/850 [00:29<00:12, 20.05it/s, loss=1.29, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  71%|███████   | 600/850 [00:29<00:12, 20.16it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  72%|███████▏  | 608/850 [00:29<00:11, 20.36it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  72%|███████▏  | 616/850 [00:29<00:11, 20.55it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  73%|███████▎  | 624/850 [00:30<00:10, 20.74it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  74%|███████▍  | 632/850 [00:30<00:10, 20.94it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  75%|███████▌  | 640/850 [00:30<00:09, 21.13it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  76%|███████▌  | 648/850 [00:30<00:09, 21.32it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  77%|███████▋  | 656/850 [00:30<00:09, 21.50it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  78%|███████▊  | 664/850 [00:30<00:08, 21.69it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  79%|███████▉  | 672/850 [00:30<00:08, 21.88it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  80%|████████  | 680/850 [00:30<00:07, 22.06it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  81%|████████  | 688/850 [00:30<00:07, 22.24it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  82%|████████▏ | 696/850 [00:31<00:06, 22.42it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  83%|████████▎ | 704/850 [00:31<00:06, 22.60it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  84%|████████▍ | 712/850 [00:31<00:06, 22.78it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  85%|████████▍ | 720/850 [00:31<00:05, 22.95it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  86%|████████▌ | 728/850 [00:31<00:05, 23.12it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  87%|████████▋ | 736/850 [00:31<00:04, 23.30it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  88%|████████▊ | 744/850 [00:31<00:04, 23.47it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  88%|████████▊ | 752/850 [00:31<00:04, 23.65it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  89%|████████▉ | 760/850 [00:31<00:03, 23.82it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  90%|█████████ | 768/850 [00:32<00:03, 23.99it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  91%|█████████▏| 776/850 [00:32<00:03, 24.16it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  92%|█████████▏| 784/850 [00:32<00:02, 24.33it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  93%|█████████▎| 792/850 [00:32<00:02, 24.50it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  94%|█████████▍| 800/850 [00:32<00:02, 24.66it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  95%|█████████▌| 808/850 [00:32<00:01, 24.83it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  96%|█████████▌| 816/850 [00:32<00:01, 24.99it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  97%|█████████▋| 824/850 [00:32<00:01, 25.16it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  98%|█████████▊| 832/850 [00:32<00:00, 25.32it/s, loss=1.29, v_num=]\n",
      "Epoch 13:  99%|█████████▉| 840/850 [00:32<00:00, 25.48it/s, loss=1.29, v_num=]\n",
      "Epoch 13: 100%|██████████| 850/850 [00:33<00:00, 25.67it/s, loss=1.29, v_num=]\n",
      "Epoch 14:  70%|███████   | 595/850 [00:29<00:12, 20.49it/s, loss=1.31, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  71%|███████   | 600/850 [00:29<00:12, 20.59it/s, loss=1.31, v_num=]\n",
      "Validating:   2%|▏         | 6/255 [00:00<00:04, 59.04it/s]\u001b[A\n",
      "Epoch 14:  72%|███████▏  | 608/850 [00:29<00:11, 20.76it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  72%|███████▏  | 616/850 [00:29<00:11, 20.94it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  73%|███████▎  | 624/850 [00:29<00:10, 21.11it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  74%|███████▍  | 632/850 [00:29<00:10, 21.29it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  75%|███████▌  | 640/850 [00:29<00:09, 21.47it/s, loss=1.31, v_num=]\n",
      "Validating:  18%|█▊        | 45/255 [00:00<00:03, 60.72it/s]\u001b[A\n",
      "Epoch 14:  76%|███████▌  | 648/850 [00:29<00:09, 21.64it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  77%|███████▋  | 656/850 [00:30<00:08, 21.81it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  78%|███████▊  | 664/850 [00:30<00:08, 21.98it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  79%|███████▉  | 672/850 [00:30<00:08, 22.15it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  80%|████████  | 680/850 [00:30<00:07, 22.32it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  81%|████████  | 688/850 [00:30<00:07, 22.49it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  82%|████████▏ | 696/850 [00:30<00:06, 22.66it/s, loss=1.31, v_num=]\n",
      "Validating:  40%|███▉      | 101/255 [00:01<00:02, 61.47it/s]\u001b[A\n",
      "Epoch 14:  83%|████████▎ | 704/850 [00:30<00:06, 22.82it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  84%|████████▍ | 712/850 [00:30<00:06, 22.98it/s, loss=1.31, v_num=]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  85%|████████▍ | 720/850 [00:31<00:05, 23.13it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  86%|████████▌ | 728/850 [00:31<00:05, 23.29it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  87%|████████▋ | 736/850 [00:31<00:04, 23.45it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  88%|████████▊ | 744/850 [00:31<00:04, 23.60it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  88%|████████▊ | 752/850 [00:31<00:04, 23.76it/s, loss=1.31, v_num=]\n",
      "Validating:  62%|██████▏   | 157/255 [00:02<00:01, 59.96it/s]\u001b[A\n",
      "Epoch 14:  89%|████████▉ | 760/850 [00:31<00:03, 23.91it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  90%|█████████ | 768/850 [00:31<00:03, 24.06it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  91%|█████████▏| 776/850 [00:32<00:03, 24.21it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  92%|█████████▏| 784/850 [00:32<00:02, 24.37it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  93%|█████████▎| 792/850 [00:32<00:02, 24.52it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  94%|█████████▍| 800/850 [00:32<00:02, 24.67it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  95%|█████████▌| 808/850 [00:32<00:01, 24.82it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  96%|█████████▌| 816/850 [00:32<00:01, 24.98it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  97%|█████████▋| 824/850 [00:32<00:01, 25.14it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  98%|█████████▊| 832/850 [00:32<00:00, 25.30it/s, loss=1.31, v_num=]\n",
      "Epoch 14:  99%|█████████▉| 840/850 [00:32<00:00, 25.46it/s, loss=1.31, v_num=]\n",
      "Epoch 14: 100%|█████████▉| 848/850 [00:33<00:00, 25.62it/s, loss=1.31, v_num=]\n",
      "Epoch 14: 100%|██████████| 850/850 [00:33<00:00, 25.65it/s, loss=1.31, v_num=]\n",
      "Epoch 15:  70%|███████   | 595/850 [00:29<00:12, 20.40it/s, loss=1.26, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  71%|███████   | 600/850 [00:29<00:12, 20.49it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  72%|███████▏  | 608/850 [00:29<00:11, 20.68it/s, loss=1.26, v_num=]\n",
      "Validating:   5%|▌         | 13/255 [00:00<00:04, 60.11it/s]\u001b[A\n",
      "Epoch 15:  72%|███████▏  | 616/850 [00:29<00:11, 20.85it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  73%|███████▎  | 624/850 [00:29<00:10, 21.03it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  74%|███████▍  | 632/850 [00:29<00:10, 21.21it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  75%|███████▌  | 640/850 [00:29<00:09, 21.39it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  76%|███████▌  | 648/850 [00:30<00:09, 21.56it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  77%|███████▋  | 656/850 [00:30<00:08, 21.73it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  78%|███████▊  | 664/850 [00:30<00:08, 21.92it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  79%|███████▉  | 672/850 [00:30<00:08, 22.11it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  80%|████████  | 680/850 [00:30<00:07, 22.29it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  81%|████████  | 688/850 [00:30<00:07, 22.48it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  82%|████████▏ | 696/850 [00:30<00:06, 22.66it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  83%|████████▎ | 704/850 [00:30<00:06, 22.81it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  84%|████████▍ | 712/850 [00:30<00:06, 22.99it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  85%|████████▍ | 720/850 [00:31<00:05, 23.17it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  86%|████████▌ | 728/850 [00:31<00:05, 23.35it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  87%|████████▋ | 736/850 [00:31<00:04, 23.52it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  88%|████████▊ | 744/850 [00:31<00:04, 23.70it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  88%|████████▊ | 752/850 [00:31<00:04, 23.87it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  89%|████████▉ | 760/850 [00:31<00:03, 24.05it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  90%|█████████ | 768/850 [00:31<00:03, 24.22it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  91%|█████████▏| 776/850 [00:31<00:03, 24.39it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  92%|█████████▏| 784/850 [00:31<00:02, 24.56it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  93%|█████████▎| 792/850 [00:32<00:02, 24.73it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  94%|█████████▍| 800/850 [00:32<00:02, 24.89it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  95%|█████████▌| 808/850 [00:32<00:01, 25.06it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  96%|█████████▌| 816/850 [00:32<00:01, 25.23it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  97%|█████████▋| 824/850 [00:32<00:01, 25.39it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  98%|█████████▊| 832/850 [00:32<00:00, 25.55it/s, loss=1.26, v_num=]\n",
      "Epoch 15:  99%|█████████▉| 840/850 [00:32<00:00, 25.72it/s, loss=1.26, v_num=]\n",
      "Epoch 15: 100%|█████████▉| 848/850 [00:32<00:00, 25.88it/s, loss=1.26, v_num=]\n",
      "Epoch 15: 100%|██████████| 850/850 [00:32<00:00, 25.90it/s, loss=1.26, v_num=]\n",
      "Epoch 16:  64%|██████▍   | 543/850 [00:26<00:14, 20.61it/s, loss=1.27, v_num=]"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from argparse import ArgumentParser, Namespace\n",
    "import wandb\n",
    "\n",
    "# import pdb\n",
    "\n",
    "parser = ArgumentParser(add_help=False)\n",
    "parser.add_argument('-wandb_run_name',\n",
    "                '--wandb_run_name',\n",
    "                help='Name of Wandb Run',\n",
    "                default='run',\n",
    "                type=str)\n",
    "parser.add_argument('-wandb_project_name',\n",
    "                    '--wandb_project_name',\n",
    "                    help='Wandb Project Name',\n",
    "                    default='deep_dream',\n",
    "                    type=str)\n",
    "parser.add_argument('-model_ckpt_path',\n",
    "                    '--model_ckpt_path',\n",
    "                    help='Model Checkpoint Path',\n",
    "                    default='./ckpts/model.ckpt',\n",
    "                    type=str)\n",
    "parser.add_argument('-wandb_log_num_iter',\n",
    "                    '--wandb_log_num_iter',\n",
    "                    help='After how many batches, we will log in training loop',\n",
    "                    default=1,\n",
    "                    type=int)\n",
    "parser.add_argument('-init_ckpt',\n",
    "                    '--init_ckpt',\n",
    "                    help='Initial Ckpt',\n",
    "                    default=None,\n",
    "                    type=str)\n",
    "\n",
    "def main(args):\n",
    "    \"\"\"Main function that will perform all the training\"\"\"\n",
    "    # init module\n",
    "    model = BeamClassifier(args)\n",
    "\n",
    "    # Using Wandblogger so that we can log our results to wandb\n",
    "    wandb.init(name=args.wandb_run_name,\n",
    "               project=args.wandb_project_name,\n",
    "               config=vars(args))\n",
    "        \n",
    "    wandb.watch(model)\n",
    "\n",
    "    # most basic trainer, uses good defaults\n",
    "    trainer = Trainer(logger=[], \n",
    "                      gpus=args.gpus, \n",
    "                      max_epochs=args.max_nb_epochs, \n",
    "                      resume_from_checkpoint=args.init_ckpt)\n",
    "#     pdb.set_trace()\n",
    "    trainer.fit(model)\n",
    "    \n",
    "    ckpt_path = os.path.join('./ckpt', f\"{args.wandb_project_name}\", f\"{args.wandb_run_name}.ckpt\")\n",
    "    ckpt_base_path = os.path.dirname(ckpt_path)\n",
    "    trainer.save_checkpoint(ckpt_path)\n",
    "    wandb.save(ckpt_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # auto add args from trainer\n",
    "    parser = Trainer.add_argparse_args(parser)\n",
    "\n",
    "    # give the module a chance to add own params\n",
    "    # good practice to define LightningModule speficic params in the module\n",
    "    parser = BeamClassifier.add_model_specific_args(parser)\n",
    "\n",
    "    # parse params\n",
    "    args= parser.parse_args(args_str)\n",
    "\n",
    "    seed_everything(123)\n",
    "\n",
    "    model = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca17d3-c83d-45d2-be81-62161fc85703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a6b02-2fe2-4955-9f9a-694bdd167c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (619)",
   "language": "python",
   "name": "619"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
