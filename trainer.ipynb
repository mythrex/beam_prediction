{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Using cached wandb-0.10.26-py2.py3-none-any.whl (2.1 MB)\n",
      "Collecting requests<3,>=2.0.0\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting configparser>=3.8.1\n",
      "  Using cached configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "Collecting psutil>=5.0.0\n",
      "  Using cached psutil-5.8.0-cp38-cp38-manylinux2010_x86_64.whl (296 kB)\n",
      "Collecting subprocess32>=3.5.3\n",
      "  Using cached subprocess32-3.5.4-py3-none-any.whl\n",
      "Collecting sentry-sdk>=0.4.0\n",
      "  Using cached sentry_sdk-1.0.0-py2.py3-none-any.whl (131 kB)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Using cached GitPython-3.1.14-py3-none-any.whl (159 kB)\n",
      "Collecting Click>=7.0\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting pathtools\n",
      "  Using cached pathtools-0.1.2-py3-none-any.whl\n",
      "Collecting PyYAML\n",
      "  Using cached PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
      "Collecting promise<3,>=2.0\n",
      "  Using cached promise-2.3-py3-none-any.whl\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Using cached shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: six>=1.13.0 in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from wandb) (1.15.0)\n",
      "Collecting protobuf>=3.12.0\n",
      "  Using cached protobuf-3.15.8-cp38-cp38-manylinux1_x86_64.whl (1.0 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from wandb) (2.8.1)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
      "Collecting smmap<5,>=3.0.1\n",
      "  Using cached smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
      "Installing collected packages: smmap, urllib3, idna, gitdb, chardet, subprocess32, shortuuid, sentry-sdk, requests, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb\n",
      "Successfully installed Click-7.1.2 GitPython-3.1.14 PyYAML-5.4.1 chardet-4.0.0 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 idna-2.10 pathtools-0.1.2 promise-2.3 protobuf-3.15.8 psutil-5.8.0 requests-2.25.1 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 urllib3-1.26.4 wandb-0.10.26\n",
      "Collecting pytorch-lightning\n",
      "  Using cached pytorch_lightning-1.2.8-py3-none-any.whl (841 kB)\n",
      "Collecting future>=0.17.1\n",
      "  Using cached future-0.18.2-py3-none-any.whl\n",
      "Collecting numpy>=1.16.6\n",
      "  Using cached numpy-1.20.2-cp38-cp38-manylinux2010_x86_64.whl (15.4 MB)\n",
      "Collecting PyYAML!=5.4.*,>=5.1\n",
      "  Using cached PyYAML-5.3.1-cp38-cp38-linux_x86_64.whl\n",
      "Collecting torchmetrics>=0.2.0\n",
      "  Using cached torchmetrics-0.2.0-py3-none-any.whl (176 kB)\n",
      "Collecting tqdm>=4.41.0\n",
      "  Using cached tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting tensorboard>=2.2.0\n",
      "  Using cached tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "Collecting torch>=1.4\n",
      "  Using cached torch-1.8.1-cp38-cp38-manylinux1_x86_64.whl (804.1 MB)\n",
      "Collecting fsspec[http]>=0.8.1\n",
      "  Using cached fsspec-2021.4.0-py3-none-any.whl (108 kB)\n",
      "Requirement already satisfied: requests in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (2.25.1)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.7.4.post0-cp38-cp38-manylinux2014_x86_64.whl (1.5 MB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.15.8)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (49.6.0.post20210108)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.29.0-py2.py3-none-any.whl (142 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.37.0-cp38-cp38-manylinux2014_x86_64.whl (4.2 MB)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.36.2)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (4.0.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.6.3-cp38-cp38-manylinux2014_x86_64.whl (324 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-5.1.0-cp38-cp38-manylinux2014_x86_64.whl (159 kB)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Using cached async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, multidict, cachetools, yarl, typing-extensions, requests-oauthlib, numpy, google-auth, attrs, async-timeout, werkzeug, torch, tensorboard-plugin-wit, markdown, grpcio, google-auth-oauthlib, fsspec, aiohttp, absl-py, tqdm, torchmetrics, tensorboard, PyYAML, future, pytorch-lightning\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "Successfully installed PyYAML-5.3.1 absl-py-0.12.0 aiohttp-3.7.4.post0 async-timeout-3.0.1 attrs-20.3.0 cachetools-4.2.1 fsspec-2021.4.0 future-0.18.2 google-auth-1.29.0 google-auth-oauthlib-0.4.4 grpcio-1.37.0 markdown-3.3.4 multidict-5.1.0 numpy-1.20.2 oauthlib-3.1.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytorch-lightning-1.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 torch-1.8.1 torchmetrics-0.2.0 tqdm-4.60.0 typing-extensions-3.7.4.3 werkzeug-1.0.1 yarl-1.6.3\n",
      "Collecting albumentations\n",
      "  Using cached albumentations-0.5.2-py3-none-any.whl (72 kB)\n",
      "Requirement already satisfied: PyYAML in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from albumentations) (5.3.1)\n",
      "Collecting scikit-image>=0.16.1\n",
      "  Using cached scikit_image-0.18.1-cp38-cp38-manylinux1_x86_64.whl (30.2 MB)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Using cached opencv_python_headless-4.5.1.48-cp38-cp38-manylinux2014_x86_64.whl (37.6 MB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.6.2-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.11.1 in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from albumentations) (1.20.2)\n",
      "Collecting imgaug>=0.4.0\n",
      "  Using cached imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "Collecting Pillow\n",
      "  Using cached Pillow-8.2.0-cp38-cp38-manylinux1_x86_64.whl (3.0 MB)\n",
      "Collecting imageio\n",
      "  Using cached imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "Requirement already satisfied: six in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n",
      "Collecting Shapely\n",
      "  Using cached Shapely-1.7.1-cp38-cp38-manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.5.1.48-cp38-cp38-manylinux2014_x86_64.whl (50.4 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.4.1-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Using cached PyWavelets-1.1.1-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Using cached tifffile-2021.4.8-py3-none-any.whl (165 kB)\n",
      "Collecting networkx>=2.0\n",
      "  Using cached networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting pyparsing>=2.2.1\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.1-cp38-cp38-manylinux1_x86_64.whl (1.2 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.8.1)\n",
      "Collecting decorator<5,>=4.3\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Installing collected packages: pyparsing, Pillow, kiwisolver, decorator, cycler, tifffile, scipy, PyWavelets, networkx, matplotlib, imageio, Shapely, scikit-image, opencv-python, opencv-python-headless, imgaug, albumentations\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.0.7\n",
      "    Uninstalling decorator-5.0.7:\n",
      "      Successfully uninstalled decorator-5.0.7\n",
      "Successfully installed Pillow-8.2.0 PyWavelets-1.1.1 Shapely-1.7.1 albumentations-0.5.2 cycler-0.10.0 decorator-4.4.2 imageio-2.9.0 imgaug-0.4.0 kiwisolver-1.3.1 matplotlib-3.4.1 networkx-2.5.1 opencv-python-4.5.1.48 opencv-python-headless-4.5.1.48 pyparsing-2.4.7 scikit-image-0.18.1 scipy-1.6.2 tifffile-2021.4.8\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-0.17.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-0.17.0\n",
      "Requirement already satisfied: torchmetrics in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: torch>=1.3.1 in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from torchmetrics) (1.8.1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from torch>=1.3.1->torchmetrics) (1.20.2)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/miniconda3/envs/619/lib/python3.8/site-packages (from torch>=1.3.1->torchmetrics) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb --upgrade\n",
    "!pip install pytorch-lightning\n",
    "!pip install albumentations\n",
    "!pip install python-dotenv\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-17 16:06:32--  https://docs.google.com/uc?export=download&confirm=9bgY&id=1mQCNp8dq499qnJI0YCc0hTVfmm4ppxO5\n",
      "Resolving docs.google.com (docs.google.com)... 142.250.67.142, 2404:6800:4009:81e::200e\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.67.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-0o-28-docs.googleusercontent.com/docs/securesc/5hrogu11ph7sqs80p2rrmvgn4diehp33/kimht97qdnksb0pp2j8ioks64oovcsip/1618675575000/18183255587859120126/11817150087953443504Z/1mQCNp8dq499qnJI0YCc0hTVfmm4ppxO5?e=download [following]\n",
      "--2021-04-17 16:06:32--  https://doc-0o-28-docs.googleusercontent.com/docs/securesc/5hrogu11ph7sqs80p2rrmvgn4diehp33/kimht97qdnksb0pp2j8ioks64oovcsip/1618675575000/18183255587859120126/11817150087953443504Z/1mQCNp8dq499qnJI0YCc0hTVfmm4ppxO5?e=download\n",
      "Resolving doc-0o-28-docs.googleusercontent.com (doc-0o-28-docs.googleusercontent.com)... 142.250.183.1, 2404:6800:4009:80d::2001\n",
      "Connecting to doc-0o-28-docs.googleusercontent.com (doc-0o-28-docs.googleusercontent.com)|142.250.183.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://docs.google.com/nonceSigner?nonce=fdr2kqhvk0occ&continue=https://doc-0o-28-docs.googleusercontent.com/docs/securesc/5hrogu11ph7sqs80p2rrmvgn4diehp33/kimht97qdnksb0pp2j8ioks64oovcsip/1618675575000/18183255587859120126/11817150087953443504Z/1mQCNp8dq499qnJI0YCc0hTVfmm4ppxO5?e%3Ddownload&hash=5le33rqoqpt2fpk4rdbkkvam159dt9lv [following]\n",
      "--2021-04-17 16:06:32--  https://docs.google.com/nonceSigner?nonce=fdr2kqhvk0occ&continue=https://doc-0o-28-docs.googleusercontent.com/docs/securesc/5hrogu11ph7sqs80p2rrmvgn4diehp33/kimht97qdnksb0pp2j8ioks64oovcsip/1618675575000/18183255587859120126/11817150087953443504Z/1mQCNp8dq499qnJI0YCc0hTVfmm4ppxO5?e%3Ddownload&hash=5le33rqoqpt2fpk4rdbkkvam159dt9lv\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.67.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://doc-0o-28-docs.googleusercontent.com/docs/securesc/5hrogu11ph7sqs80p2rrmvgn4diehp33/kimht97qdnksb0pp2j8ioks64oovcsip/1618675575000/18183255587859120126/11817150087953443504Z/1mQCNp8dq499qnJI0YCc0hTVfmm4ppxO5?e=download&nonce=fdr2kqhvk0occ&user=11817150087953443504Z&hash=hssscs4nnfnc65hs03k31kbog2jlpirv [following]\n",
      "--2021-04-17 16:06:33--  https://doc-0o-28-docs.googleusercontent.com/docs/securesc/5hrogu11ph7sqs80p2rrmvgn4diehp33/kimht97qdnksb0pp2j8ioks64oovcsip/1618675575000/18183255587859120126/11817150087953443504Z/1mQCNp8dq499qnJI0YCc0hTVfmm4ppxO5?e=download&nonce=fdr2kqhvk0occ&user=11817150087953443504Z&hash=hssscs4nnfnc65hs03k31kbog2jlpirv\n",
      "Connecting to doc-0o-28-docs.googleusercontent.com (doc-0o-28-docs.googleusercontent.com)|142.250.183.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/x-gzip]\n",
      "Saving to: ‘download.tar.gz’\n",
      "\n",
      "download.tar.gz         [        <=>         ]   3.53G  50.9MB/s    in 83s     \n",
      "\n",
      "2021-04-17 16:07:56 (43.8 MB/s) - ‘download.tar.gz’ saved [3793541120]\n",
      "\n",
      "./Dataset_-17.3375dB/\n",
      "./Dataset_-17.3375dB/-17.3375dB_labelTrain.npy\n",
      "./Dataset_-17.3375dB/-17.3375dB_highFreqChVal.npy\n",
      "./Dataset_-17.3375dB/-17.3375dB_trainInpLoc.npy\n",
      "./Dataset_-17.3375dB/-17.3375dB_labelVal.npy\n",
      "./Dataset_-17.3375dB/-17.3375dB_trainOutLoc.npy\n",
      "./Dataset_-17.3375dB/-17.3375dB_maxRateVal.npy\n",
      "./Dataset_-17.3375dB/-17.3375dB_inpTrain.npy\n",
      "./Dataset_-17.3375dB/-17.3375dB_valInpLoc.npy\n",
      "./Dataset_-17.3375dB/-17.3375dB_inpVal.npy\n",
      "./Dataset_-17.3375dB/-17.3375dB_valOutLoc.npy\n",
      "./Dataset_-17.3375dB/-17.3375dB_highFreqChTrain.npy\n",
      "./Dataset_-17.3375dB/-17.3375dB_maxRateTrain.npy\n"
     ]
    }
   ],
   "source": [
    "# https://drive.google.com/file/d//view?usp=sharing\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1mQCNp8dq499qnJI0YCc0hTVfmm4ppxO5' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1mQCNp8dq499qnJI0YCc0hTVfmm4ppxO5\" -O \"download.tar.gz\" && rm -rf /tmp/cookies.txt\n",
    "!tar -xvf download.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import pdb\n",
    "\n",
    "# def calc_acc(pred: torch.tensor, y: torch.tensor, num_classes: int, return_class_wise_acc: bool = False):    pred = pred.argmax(1)\n",
    "#     class_wise_acc = []\n",
    "#     for i in range(num_classes):\n",
    "#         tp = ((pred == i) & (y == i)).sum().float()\n",
    "#         tn = ((pred != i) & (y != i)).sum().float()\n",
    "#         fp = ((pred == i) & (y != i)).sum().float()\n",
    "#         fn = ((pred != i) & (y == i)).sum().float()\n",
    "#         acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "#         class_wise_acc.append(acc)\n",
    "    \n",
    "# #     pdb.set_trace()\n",
    "#     class_wise_acc = torch.Tensor(class_wise_acc)\n",
    "#     if return_class_wise_acc:\n",
    "#         return class_wise_acc\n",
    "#     return class_wise_acc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamPredictionDataset(Dataset):\n",
    "    \"\"\"Beam Prediction dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, file_path: str,\n",
    "                 label_file_path: str,\n",
    "                 reshape: bool=False,\n",
    "                 transforms: Optional[transforms.Compose] = None,\n",
    "                 preprocessing_fn: Optional[transforms.Compose] = None) -> None:\n",
    "        \"\"\"\n",
    "        Init the Dataset\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.label_file_path = label_file_path\n",
    "        \n",
    "        self.data = np.load(file_path)\n",
    "        self.data = self.data.transpose((1, 0))\n",
    "        \n",
    "        self.label = np.load(label_file_path)\n",
    "#         pdb.set_trace()\n",
    "        \n",
    "        assert len(self.label) == len(self.data)\n",
    "        # reshape is true\n",
    "        # num_users x num_channels x num_antennas x real/imaginary\n",
    "        if reshape:\n",
    "            self.data = self.data.reshape((2, 4, 32, -1))\n",
    "            self.data = self.data.transpose((3, 2, 1, 0))\n",
    "            \n",
    "        self.preprocessing_fn = preprocessing_fn\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the total length of dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Gets an item from dataset\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        user_data = self.data[idx]\n",
    "        \n",
    "        if self.preprocessing_fn is not None:\n",
    "            user_data = self.preprocessing_fn(user_data)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            user_data = self.transforms(user_data)\n",
    "        \n",
    "        label = self.label[idx]\n",
    "        label = torch.Tensor(label).type(torch.int64) - 1\n",
    "        return user_data, label\n",
    "    \n",
    "def transform(x: np.array) -> torch.Tensor:\n",
    "    # mean normalize\n",
    "    x -= x.mean()\n",
    "    x /= x.std()\n",
    "    x = torch.Tensor(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 1.1344,  1.1642,  0.8118,  0.1093, -0.2929,  0.3619,  1.0790,  1.3874,\n",
      "         1.2894,  1.1469,  1.3742,  0.6998, -0.4009,  0.3625,  0.8699,  1.1849,\n",
      "         0.6786,  1.1753,  1.1628,  1.0550, -0.8943, -0.7125,  0.3022,  1.0900,\n",
      "         0.8706,  1.3478,  1.5702,  0.9558, -1.6566, -0.7382,  0.0148,  0.6442,\n",
      "         0.3017,  0.8905,  0.9791,  1.1644, -0.9876, -0.7922, -0.4629,  0.3374,\n",
      "        -0.0516,  0.6355,  1.2137,  1.3104, -1.2456, -1.1153, -1.0029,  0.0712,\n",
      "        -0.3255,  0.3647,  1.0288,  1.1176, -1.1510, -1.2242, -1.2269, -0.4542,\n",
      "        -0.7970, -0.4256,  0.9413,  1.4918, -0.9748, -1.5398, -1.6161, -0.4450,\n",
      "        -1.1006, -0.9013,  0.4272,  1.0205, -0.8424, -1.2304, -1.5746, -1.4980,\n",
      "        -1.5050, -0.9478, -0.2943,  0.4626, -0.4176, -1.3170, -1.5857, -1.3130,\n",
      "        -1.2471, -1.1989, -0.6621,  0.2399, -0.2827, -1.0135, -1.6343, -1.5665,\n",
      "        -1.4390, -1.5518, -0.7836, -0.4450, -0.0606, -0.6873, -1.3370, -2.0944,\n",
      "        -1.3866, -1.2450, -1.3194, -0.6425,  0.7051, -0.0322, -1.0300, -1.2306,\n",
      "        -0.6418, -1.6214, -1.3991, -0.9170,  0.9509,  0.4661, -0.6956, -0.8484,\n",
      "        -0.9170, -1.3425, -1.5632, -1.4795,  1.4220,  0.5489,  0.4026, -0.5844,\n",
      "        -0.6274, -1.2085, -1.7199, -1.2470,  1.5720,  1.2481,  0.3709,  0.0025,\n",
      "         0.3596, -0.8391, -1.3560, -1.4393,  1.5227,  1.0183,  0.8746, -0.1959,\n",
      "         0.3806, -0.0644, -1.1502, -1.6148,  1.1727,  1.3091,  1.0675,  0.4314,\n",
      "         1.0033,  0.0746, -0.6809, -1.2830,  1.1760,  1.6166,  1.5842,  0.6260,\n",
      "         1.1363,  0.2335, -0.0576, -1.0852,  0.6769,  1.3474,  1.4323,  1.1049,\n",
      "         1.5561,  0.5584,  0.0851, -0.4431,  0.5574,  0.8314,  1.7251,  0.9947,\n",
      "         1.3336,  1.2545,  0.2566, -0.4365, -0.1540,  0.6379,  1.1497,  1.0744,\n",
      "         1.1799,  1.3945,  0.7851,  0.2137, -0.2622,  0.1544,  1.4368,  1.8656,\n",
      "         1.3089,  1.3896,  1.0659,  0.2861, -0.3666,  0.1218,  0.7796,  1.2413,\n",
      "         1.2102,  1.3221,  1.0344,  0.9304, -1.0877, -0.1499,  0.3859,  1.0914,\n",
      "         0.4617,  0.7131,  1.6144,  1.1880, -1.0281, -1.3422,  0.1930,  0.9728,\n",
      "         0.1454,  0.8132,  1.3767,  0.8216, -1.3210, -0.6237, -0.2125, -0.0454,\n",
      "        -0.3330,  0.3443,  0.7524,  0.9035, -1.2856, -0.2620, -0.4970, -0.2679,\n",
      "        -0.8429,  0.5761,  0.9023,  1.2007, -1.4464, -1.1691, -0.6407, -0.2095,\n",
      "        -0.7193,  0.1202,  0.4905,  1.4410, -1.2580, -1.2274, -1.1168, -0.4818,\n",
      "        -0.5149, -0.4690,  0.3170,  0.8014, -0.6843, -1.1411, -0.9833, -0.9430,\n",
      "        -0.6822, -0.7225, -0.5029,  0.7130, -0.4280, -0.8024, -1.1280, -0.9917]), tensor([36]))\n"
     ]
    }
   ],
   "source": [
    "# example ds\n",
    "\n",
    "ds = BeamPredictionDataset(\n",
    "    file_path='./Dataset_-17.3375dB/-17.3375dB_inpTrain.npy',\n",
    "    label_file_path='./Dataset_-17.3375dB/-17.3375dB_labelTrain.npy',\n",
    "    transforms=transform\n",
    ")\n",
    "it = iter(ds)\n",
    "out = next(it)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "import wandb\n",
    "from argparse import ArgumentParser\n",
    "from typing import Tuple\n",
    "from torchmetrics import Accuracy, Precision, Recall\n",
    "\n",
    "import torchmetrics \n",
    "import pdb\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class BeamClassifier(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, hparams) -> None:\n",
    "        \"\"\"\n",
    "        Downloading Backbone and defining structure of model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # args from argparser\n",
    "        self.hparams = hparams\n",
    "        in_ch = self.hparams.in_ch\n",
    "        out_ch = self.hparams.out_ch\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_ch, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(2048, out_ch),\n",
    "        )\n",
    "        self._acc_metric = torchmetrics.Accuracy()\n",
    "        self._top2_acc_metric = torchmetrics.Accuracy(top_k=2)\n",
    "        self._precision = Precision(average='macro', \n",
    "                                   num_classes=self.hparams.out_ch)\n",
    "        self._recall = Recall(average='macro', \n",
    "                             num_classes=self.hparams.out_ch)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Forward step of model.\n",
    "        \"\"\"\n",
    "#         pdb.set_trace()\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def loss_fn(self, pred: torch.Tensor, y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Loss function used for model\"\"\"\n",
    "        y_sq = y.squeeze(-1)\n",
    "        loss = F.cross_entropy(pred, y_sq)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self) -> torch.optim:\n",
    "        # REQUIRED\n",
    "        # can return multiple optimizers and learning_rate schedulers\n",
    "        opt = torch.optim.Adam(self.model.parameters(),\n",
    "                               lr=self.hparams.learning_rate)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            opt, self.hparams.max_nb_epochs, self.hparams.learning_rate)\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "#         lr_scheduler = None\n",
    "        return [opt], [lr_scheduler]\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Define the data loader for training data\"\"\"\n",
    "        # REQUIRED\n",
    "        return DataLoader(BeamPredictionDataset(\n",
    "                                file_path='./Dataset_-17.3375dB/-17.3375dB_inpTrain.npy',\n",
    "                                label_file_path='./Dataset_-17.3375dB/-17.3375dB_labelTrain.npy',\n",
    "                                transforms=transform\n",
    "                            ),\n",
    "                          batch_size=self.hparams.batch_size,\n",
    "                          num_workers=self.hparams.num_workers,\n",
    "                          shuffle=True)\n",
    "\n",
    "    def training_step(self, batch: list, batch_idx: int) -> dict:\n",
    "        \"\"\"Backward step of model\"\"\"\n",
    "        # REQUIRED\n",
    "        x, y = batch\n",
    "        pred = self.forward(x)\n",
    "\n",
    "        loss = self.loss_fn(pred, y)\n",
    "        \n",
    "        pred = F.softmax(pred, dim=-1)\n",
    "        y_sq = y.squeeze(-1)\n",
    "        \n",
    "        # metrics\n",
    "        acc = self._acc_metric(pred, y_sq)\n",
    "        prec = self._precision(pred, y_sq)\n",
    "        rec = self._recall(pred, y_sq)\n",
    "        \n",
    "        if self.lr_scheduler is not None:\n",
    "            lr = self.lr_scheduler.get_last_lr()[0]\n",
    "\n",
    "        if(batch_idx % self.hparams.wandb_log_num_iter == 0):\n",
    "            wandb.log({\n",
    "                'train_loss': loss,\n",
    "            })\n",
    "            \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'train_acc': acc,\n",
    "            'train_prec': prec,\n",
    "            'train_rec': rec\n",
    "        }\n",
    "    \n",
    "    def training_epoch_end(self, outputs: list) -> None:\n",
    "        acc = torch.stack([x['train_acc'] for x in outputs]).mean()\n",
    "        prec = torch.stack([x['train_prec'] for x in outputs]).mean()\n",
    "        rec = torch.stack([x['train_rec'] for x in outputs]).mean()\n",
    "        \n",
    "        if self.lr_scheduler is not None:\n",
    "            lr = self.lr_scheduler.get_last_lr()[0]\n",
    "        else:\n",
    "            lr = self.hparams.learning_rate\n",
    "        logs = {\n",
    "            'lr': lr,\n",
    "            'train_acc': acc,\n",
    "            'train_prec': prec,\n",
    "            'train_rec': rec\n",
    "        }\n",
    "        wandb.log(logs)\n",
    "        self.log_dict(logs)\n",
    "    \n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Define the data loader for validation data\"\"\"\n",
    "        # OPTIONAL\n",
    "        return DataLoader(BeamPredictionDataset(\n",
    "                                file_path='./Dataset_-17.3375dB/-17.3375dB_inpVal.npy',\n",
    "                                label_file_path='./Dataset_-17.3375dB/-17.3375dB_labelVal.npy',\n",
    "                                transforms=transform\n",
    "                            ),\n",
    "                          batch_size=self.hparams.batch_size,\n",
    "                          num_workers=self.hparams.num_workers\n",
    "                         )\n",
    "\n",
    "    def validation_step(self, batch: list, batch_idx: torch.Tensor) -> dict:\n",
    "        \"\"\"Validation step to be carried out on validation data.\"\"\"\n",
    "        # REQUIRED\n",
    "        # pdb.set_trace()\n",
    "        x, y = batch\n",
    "        \n",
    "        pred = self.forward(x)\n",
    "\n",
    "        loss = self.loss_fn(pred, y)\n",
    "        \n",
    "        pred = F.softmax(pred, dim=-1)\n",
    "        y_sq = y.squeeze(-1)\n",
    "        \n",
    "        acc = self._acc_metric(pred, y_sq)\n",
    "        prec = self._precision(pred, y_sq)\n",
    "        rec = self._recall(pred, y_sq)\n",
    "\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc,\n",
    "            'val_prec': prec,\n",
    "            'val_rec': rec\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs: list) -> None:\n",
    "        \"\"\"Use results from each validation step to generate validation stats at epoch end\"\"\"\n",
    "        val_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        val_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        val_prec = torch.stack([x['val_prec'] for x in outputs]).mean()\n",
    "        val_rec = torch.stack([x['val_rec'] for x in outputs]).mean()\n",
    "        \n",
    "        logs = {\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'val_prec': val_prec,\n",
    "            'val_rec': val_rec\n",
    "        }\n",
    "        wandb.log(logs)\n",
    "        self.log_dict(logs)\n",
    "    \n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Define the data loader for test data\"\"\"\n",
    "        print(\"Test Dataloader\")\n",
    "        # OPTIONAL\n",
    "        return DataLoader(BeamPredictionDataset(\n",
    "                                file_path='./Dataset_-17.3375dB/-17.3375dB_inpVal.npy',\n",
    "                                label_file_path='./Dataset_-17.3375dB/-17.3375dB_labelVal.npy',\n",
    "                                transforms=transform\n",
    "                            ),\n",
    "                          batch_size=self.hparams.batch_size,\n",
    "                          num_workers=self.hparams.num_workers\n",
    "                         )\n",
    "    \n",
    "    def test_step(self, batch: list, batch_idx: torch.Tensor) -> dict:\n",
    "        \"\"\"Validation step to be carried out on validation data.\"\"\"\n",
    "        # REQUIRED\n",
    "        # pdb.set_trace()\n",
    "        x, y = batch\n",
    "        \n",
    "        pred = self.forward(x)        \n",
    "        pred = F.softmax(pred, dim=-1)\n",
    "        y_sq = y.squeeze(-1)\n",
    "        logs = {\n",
    "            'pred': pred,\n",
    "            'ground_truth': y_sq\n",
    "        }\n",
    "#         self.log_dict(logs)\n",
    "        return logs\n",
    "    \n",
    "    def test_epoch_end(self, outputs: list) -> None:\n",
    "        \"\"\"Use results from each validation step to generate validation stats at epoch end\"\"\"\n",
    "        pred = torch.cat([x['pred'] for x in outputs], dim=0)\n",
    "        ground_truth = torch.cat([x['ground_truth'] for x in outputs], dim=0)\n",
    "#         pdb.set_trace()\n",
    "        top1_acc = self._acc_metric(pred, ground_truth)\n",
    "        top2_acc = self._top2_acc_metric(pred, ground_truth)\n",
    "        ax = wandb.plot.confusion_matrix(\n",
    "                        y_true=ground_truth.tolist(),\n",
    "                        preds=pred.argmax(-1).tolist(),\n",
    "                        class_names=list(map(lambda x: str(x), \n",
    "                                             range(self.hparams.out_ch))))\n",
    "        logs = {\n",
    "            'top1_acc': top1_acc,\n",
    "            'top2_acc': top2_acc,\n",
    "            'conf_matrix': ax\n",
    "        }\n",
    "        wandb.log(logs)\n",
    "    \n",
    "\n",
    "    def load_encoder_weights(self) -> None:\n",
    "        \"\"\"Loads encoder weights from ckpt\"\"\"\n",
    "        ckpt = torch.load(self.hparams.encoder_ckpt_path)\n",
    "        pretrained_dict = ckpt['state_dict']\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if (\n",
    "            'encoder' in k) and (k in model_dict)}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.load_state_dict(model_dict)\n",
    "\n",
    "    def load_model_weights_from_ckpt(self) -> None:\n",
    "        \"\"\"Load model weights to model on cpu\"\"\"\n",
    "        ckpt = torch.load(self.hparams.model_ckpt_path,\n",
    "                          map_location=torch.device('cpu'))\n",
    "        pretrained_dict = ckpt['state_dict']\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k,\n",
    "                           v in pretrained_dict.items() if (k in model_dict)}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.load_state_dict(model_dict)\n",
    "        \n",
    "    def _get_learning_rate(self) -> float:\n",
    "        i = 0\n",
    "        for param_group in self._optimizer.param_groups:\n",
    "            if i == 0:\n",
    "                learning_rate = param_group[\"lr\"]\n",
    "            else:\n",
    "                if learning_rate != param_group[\"lr\"]:\n",
    "                    raise ValueError(\n",
    "                        \"different param groups have different lr\")\n",
    "        return learning_rate\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n",
    "        \"\"\"\n",
    "        Specify the hyperparams for this LightningModule\n",
    "        \"\"\"\n",
    "        # MODEL specific arguments\n",
    "        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "        parser.add_argument('--learning_rate', default=0.02, type=float)\n",
    "        parser.add_argument('--batch_size', default=32, type=int)\n",
    "        parser.add_argument('--in_ch', default=256, type=int)\n",
    "        parser.add_argument('--out_ch', default=64, type=int)\n",
    "        parser.add_argument('--num_workers', default=1, type=int)\n",
    "        parser.add_argument('--max_nb_epochs', default=1, type=int)\n",
    "        return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5697)\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser, Namespace\n",
    "args_str = [\n",
    "        # model related args\n",
    "        '--max_nb_epochs=1',\n",
    "        '--learning_rate=1e-3',\n",
    "        '--batch_size=16',\n",
    "        '--in_ch=256',\n",
    "        '--out_ch=64',\n",
    "        '--num_workers=4'\n",
    "]\n",
    "parser = ArgumentParser(add_help=False)\n",
    "parser = BeamClassifier.add_model_specific_args(parser)\n",
    "args= parser.parse_args(args_str)\n",
    "\n",
    "model = BeamClassifier(args)\n",
    "train_dl = model.train_dataloader()\n",
    "it = iter(train_dl)\n",
    "x, y = next(it)\n",
    "\n",
    "\n",
    "pred = model(x)\n",
    "loss = model.loss_fn(pred, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_str = ['--tpu_cores=0',\n",
    "        '--progress_bar_refresh_rate=20',\n",
    "        '--wandb_run_name=baseline',\n",
    "        '--wandb_project_name=Beam Prediction',\n",
    "        '--wandb_log_num_iter=1',\n",
    "        '--gpus=1',\n",
    "        # model related args\n",
    "        '--max_nb_epochs=1',\n",
    "        '--learning_rate=1e-2',\n",
    "        '--batch_size=128',\n",
    "        '--in_ch=256',\n",
    "        '--out_ch=64',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "PROJECT_ROOT = os.path.dirname(os.path.abspath('.'))\n",
    "load_dotenv(dotenv_path=os.path.join(PROJECT_ROOT, '.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3a5xgpm0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 30513<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ubuntu/619/wandb/run-20210417_180127-3a5xgpm0/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ubuntu/619/wandb/run-20210417_180127-3a5xgpm0/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>val_loss</td><td>1.35427</td></tr><tr><td>val_acc</td><td>0.43254</td></tr><tr><td>val_prec</td><td>0.28169</td></tr><tr><td>val_rec</td><td>0.33883</td></tr><tr><td>_runtime</td><td>19</td></tr><tr><td>_timestamp</td><td>1618682509</td></tr><tr><td>_step</td><td>597</td></tr><tr><td>train_loss</td><td>1.64602</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_acc</td><td>0.25173</td></tr><tr><td>train_prec</td><td>0.16955</td></tr><tr><td>train_rec</td><td>0.20033</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>val_loss</td><td>█▁</td></tr><tr><td>val_acc</td><td>▁█</td></tr><tr><td>val_prec</td><td>▁█</td></tr><tr><td>val_rec</td><td>▁█</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▇▅▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_prec</td><td>▁</td></tr><tr><td>train_rec</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">baseline</strong>: <a href=\"https://wandb.ai/sagarkaushik98/Beam%20Prediction/runs/3a5xgpm0\" target=\"_blank\">https://wandb.ai/sagarkaushik98/Beam%20Prediction/runs/3a5xgpm0</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3a5xgpm0). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">baseline</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sagarkaushik98/Beam%20Prediction\" target=\"_blank\">https://wandb.ai/sagarkaushik98/Beam%20Prediction</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sagarkaushik98/Beam%20Prediction/runs/11sewvad\" target=\"_blank\">https://wandb.ai/sagarkaushik98/Beam%20Prediction/runs/11sewvad</a><br/>\n",
       "                Run data is saved locally in <code>/home/ubuntu/619/wandb/run-20210417_180532-11sewvad</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataloader\n",
      "Testing: 100%|██████████| 255/255 [07:04<00:00,  1.66s/it]\n",
      "Testing: 100%|██████████| 255/255 [04:51<00:00,  1.14s/it]\n",
      "Testing: 100%|██████████| 255/255 [00:07<00:00, 34.45it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from argparse import ArgumentParser, Namespace\n",
    "import wandb\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# import pdb\n",
    "\n",
    "parser = ArgumentParser(add_help=False)\n",
    "parser.add_argument('-wandb_run_name',\n",
    "                '--wandb_run_name',\n",
    "                help='Name of Wandb Run',\n",
    "                default='run',\n",
    "                type=str)\n",
    "parser.add_argument('-wandb_project_name',\n",
    "                    '--wandb_project_name',\n",
    "                    help='Wandb Project Name',\n",
    "                    default='deep_dream',\n",
    "                    type=str)\n",
    "parser.add_argument('-model_ckpt_path',\n",
    "                    '--model_ckpt_path',\n",
    "                    help='Model Checkpoint Path',\n",
    "                    default='./ckpts/model.ckpt',\n",
    "                    type=str)\n",
    "parser.add_argument('-wandb_log_num_iter',\n",
    "                    '--wandb_log_num_iter',\n",
    "                    help='After how many batches, we will log in training loop',\n",
    "                    default=1,\n",
    "                    type=int)\n",
    "parser.add_argument('-init_ckpt',\n",
    "                    '--init_ckpt',\n",
    "                    help='Initial Ckpt',\n",
    "                    default=None,\n",
    "                    type=str)\n",
    "\n",
    "def main(args):\n",
    "    \"\"\"Main function that will perform all the training\"\"\"\n",
    "    # init module\n",
    "    model = BeamClassifier(args)\n",
    "\n",
    "    # Using Wandblogger so that we can log our results to wandb\n",
    "    wandb.init(name=args.wandb_run_name,\n",
    "               project=args.wandb_project_name,\n",
    "               config=vars(args))\n",
    "        \n",
    "    wandb.watch(model)\n",
    "\n",
    "    # most basic trainer, uses good defaults\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_loss',\n",
    "        dirpath='./ckpts',\n",
    "        filename='{epoch:02d}-{val_loss:.2f}'\n",
    "    )\n",
    "    trainer = Trainer(logger=[], \n",
    "                      gpus=args.gpus, \n",
    "                      max_epochs=args.max_nb_epochs, \n",
    "                      resume_from_checkpoint=args.init_ckpt)\n",
    "#     pdb.set_trace()\n",
    "    trainer.fit(model)\n",
    "    trainer.test(model)\n",
    "    \n",
    "    ckpt_path = os.path.join('./ckpt', f\"{args.wandb_project_name}\", f\"{args.wandb_run_name}.ckpt\")\n",
    "    ckpt_base_path = os.path.dirname(ckpt_path)\n",
    "    trainer.save_checkpoint(ckpt_path)\n",
    "    wandb.save(ckpt_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # auto add args from trainer\n",
    "    parser = Trainer.add_argparse_args(parser)\n",
    "\n",
    "    # give the module a chance to add own params\n",
    "    # good practice to define LightningModule speficic params in the module\n",
    "    parser = BeamClassifier.add_model_specific_args(parser)\n",
    "\n",
    "    # parse params\n",
    "    args= parser.parse_args(args_str)\n",
    "\n",
    "    seed_everything(123)\n",
    "\n",
    "    model = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "619",
   "language": "python",
   "name": "619"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "cbfaa0c31130d6fe797b1b315fd7af716006f03c19477746c82c11dfd72f132a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
